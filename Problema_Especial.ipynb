{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problema Especial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfgf11/Problema-Especial/blob/master/Problema_Especial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtf-HdYxvLE9",
        "colab_type": "code",
        "outputId": "60f79aca-0ecf-467e-bd0f-33c2d43e7950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Se monta el Drive para importar y guardar los datos y modelos.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')#,force_remount = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKEEuc5e9DuD",
        "colab_type": "code",
        "outputId": "ac6570d4-2153-47c6-9399-b48ae531ff4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Se instalan las librerias necesarias\n",
        "!pip install librosa\n",
        "!pip install progressbar2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.14.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.1)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.12.0)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.47.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.8)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.17.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (45.1.0)\n",
            "Requirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.31.0)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (3.38.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from progressbar2) (1.12.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2) (2.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqWuMaqiELzW",
        "colab_type": "text"
      },
      "source": [
        "# Importar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV__vdiK4GUH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "68f2f518-1093-40e0-af6e-93dc611697fd"
      },
      "source": [
        "# Tensor Flow\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import AveragePooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import SVG\n",
        "\n",
        "# Recopilacion de datos\n",
        "import xml.dom.minidom\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "\n",
        "# Para el preprocesamiento\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "\n",
        "import librosa\n",
        "import progressbar\n",
        "\n",
        "\n",
        "# Import libraries \n",
        "import librosa.display\n",
        "from matplotlib.pyplot import specgram\n",
        "import pandas as pd\n",
        "import glob \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import IPython.display as ipd  # To play sound in the notebook\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLQEssmxVerC",
        "colab_type": "text"
      },
      "source": [
        "# Recopilación de Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwMARXzLvh-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rutaDatosTraining = \"drive/My Drive/MIVIA_DB4_dist/training\"\n",
        "rutaDatosTrainingSounds = \"drive/My Drive/MIVIA_DB4_dist/training/sounds\"\n",
        "nXML=66 # Numero de archivos XML\n",
        "nAudios=nXML*8 # Numero de audios totales\n",
        "def ObtenerSonidos(pNXML=1,nAudios=5, Tv=0.032, advance_V=4): #Tv es la ventana de tiempo de cada muestra (32ms), advance_V es el salto de tiempo (32ms/4)\n",
        "  NMV = round(Tv*32000) # Numero de muestras por ventana\n",
        "  NMV_advance = round(NMV/advance_V) # Numero de muestras por las cuales se avanza\n",
        "  window = np.hamming(NMV)\n",
        "\n",
        "  datos_x_totales=np.zeros((1,NMV))\n",
        "  datos_y_totales=np.zeros(1)\n",
        "  contador=0\n",
        "  with progressbar.ProgressBar(max_value=pNXML*nAudios) as bar:\n",
        "    for i in range(1,(pNXML+1)):\n",
        "        if i<10: # Se hace esto debido que en los audios hay elementos 00001_01 y 00010_1\n",
        "          h=\"0\"\n",
        "        else:\n",
        "          h=\"\"\n",
        "        doc = xml.dom.minidom.parse(rutaDatosTraining + \"/000\" + h + str(i) + \".xml\")\n",
        "        start = doc.getElementsByTagName(\"STARTSECOND\") #Vector que contiene el tiempo en segundos de inicio de todos los venetos \n",
        "        finish = doc.getElementsByTagName(\"ENDSECOND\") #Vector que contiene el tiempo en segundos de finalizacion de todos los eventos\n",
        "        ID = doc.getElementsByTagName(\"CLASS_ID\") # Vector que contiene la etiqueta de cada uno de los eventos\n",
        "        events = doc.getElementsByTagName(\"events\") # Indica informacion de todos los eventos en un archivo xml (tamaño)\n",
        "        a, b, c, d=(events[0].attributes[\"size\"].value) #Se obtiene el numero de eventos en un audio\n",
        "        nEventos = int(c+d) # numero de eventos en un audio\n",
        "        for a in range(0,nAudios):# Numero de audios por xml\n",
        "          if a<2: # Se hace esto debido que en los audios hay elementos 00001_01 y 00010_1\n",
        "            r = \"0\"\n",
        "            t=str(a)\n",
        "          else:\n",
        "            t=str(a-1)\n",
        "            r=\"\"\n",
        "          fs, frameData = wavfile.read(rutaDatosTrainingSounds + '/000' + h + str(i) +'_'+ r + t +'.wav') #Audio seleccionado\n",
        "          datos_x = (librosa.util.frame(frameData, frame_length=NMV, hop_length=NMV_advance)).T # Datos transpuestos\n",
        "          datos_y = np.zeros(len(datos_x)) #Etiquetas de cada uno de los datos, los datos no asignados serán 0 y corresponderan a sonido ambiente\n",
        "          for j in range(0,nEventos): # Se recorre el numero de eventos para cada xml\n",
        "            startFrame = float(str(start[j].firstChild.data))*fs #Posicion inicial de evento con respecto a frameData\n",
        "            endFrame = float(str(finish[j].firstChild.data))*fs #Posicion final de evento con respecto a frameData\n",
        "            label = ID[j].firstChild.data #etiqueta del evento\n",
        "            \n",
        "            datos_y[round((startFrame-NMV)/NMV_advance):round((endFrame-NMV)/NMV_advance)]=int(label)  #Se crea el vector de etiquetas\n",
        "          contador+=1\n",
        "          #datos_x_totales = np.r_[datos_x[datos_y!=0,:],datos_x_totales] #Para este escenario se estan ignorando los datos de backgroud\n",
        "          #datos_y_totales = np.r_[datos_y[datos_y!=0],datos_y_totales]\n",
        "          datos_x_totales = np.r_[datos_x,datos_x_totales] #Se toman los datos de background, hay desbalance\n",
        "          datos_y_totales = np.r_[datos_y,datos_y_totales]\n",
        "          bar.update(contador) #Se actualiza la barra de progreso\n",
        "    datos_x_totales = datos_x_totales*window #Se pasa cada uno de los datos por una ventana de hamming\n",
        "    datos_x_totales = datos_x_totales[0:-1,:]\n",
        "    datos_y_totales = datos_y_totales[0:-1]\n",
        "    datos_y_totales[datos_y_totales==4] = 1\n",
        "  return datos_x_totales, datos_y_totales"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INB19Yue-LQT",
        "colab_type": "code",
        "outputId": "d241b93a-15c6-43b5-c916-ad7c00bcb9ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x,y=ObtenerSonidos(pNXML=10,nAudios=5, Tv=0.032, advance_V=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (50 of 50) |########################| Elapsed Time: 0:01:33 Time:  0:01:33\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymL3G0l3YEWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"drive/My Drive/MIVIA_DB4_dist/x_train_10xml_5Audios\", x)\n",
        "np.save(\"drive/My Drive/MIVIA_DB4_dist/y_train_10xml_5Audios\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgWAcY2YVhvk",
        "colab_type": "text"
      },
      "source": [
        "Se extraen los datos guardados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjPvwYgoaJvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=np.load(\"drive/My Drive/MIVIA_DB4_dist/x_train_10xml_5Audios.npy\")\n",
        "y=np.load(\"drive/My Drive/MIVIA_DB4_dist/y_train_10xml_5Audios.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z681W-eubjJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.sum(y==3)\n",
        "y[y==2]=0\n",
        "y[y==3]=2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlXJ9xvrWOvH",
        "colab_type": "text"
      },
      "source": [
        "# Preprocesamiento de los datos\n",
        "Aquí se debe realizar todo el preprocesamiento de los datos. Se debe considerar el desbalance en los datos de entrenamiento. Primero se separan los datos de entrenamiento y validación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1OKZiZQVnUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y , random_state = 0, test_size=0.20)\n",
        "x=[]\n",
        "y=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXoqbJrtYEPC",
        "colab_type": "text"
      },
      "source": [
        "Random under Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erkI7P6UWdCd",
        "colab_type": "code",
        "outputId": "438e7d04-1438-4960-943b-fa38030256ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print('Original dataset shape %s' % Counter(y_train))\n",
        "\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "x_train, y_train = rus.fit_resample(x_train, y_train)\n",
        "\n",
        "print('Resampled dataset shape %s' % Counter(y_train))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original dataset shape Counter({0.0: 816870, 1.0: 75361, 2.0: 25073})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 25073, 1.0: 25073, 2.0: 25073})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV9GnndmcxxW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Random Over Sampler.\n",
        "\n",
        "\n",
        "Esto va a hacer que todo colapse si hay muchos datos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZv1PirZcxP5",
        "colab_type": "code",
        "outputId": "4a9da902-2297-443f-94fe-7c6d78fa14f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print('Original dataset shape %s' % Counter(y_train))\n",
        "print(\"Oversampling...\")\n",
        "\n",
        "randomOverSampler = RandomOverSampler(sampling_strategy = 'not majority', random_state = 0)\n",
        "x_train, y_train = randomOverSampler.fit_resample(x_train, y_train)\n",
        "\n",
        "print(\"Reshaping...\")\n",
        "print('Resampled dataset shape %s' % Counter(y_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original dataset shape Counter({0.0: 816870, 1.0: 75361, 2.0: 25073})\n",
            "Oversampling...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-YNTQpwZ80L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.reshape(x_train, (-1, 1024, 1), 'F')\n",
        "x_test = np.reshape(x_test, (-1, 1024, 1), 'F')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MuYTEDh0F-i",
        "colab_type": "text"
      },
      "source": [
        "# Modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckWibGKPOSF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crearModelo(pTasa, pAlpha, pNumFiltros, pTamFiltros, pTamPooling, pNumNeuronas, pOptimizer):\n",
        "\n",
        "  capaEntrada = Input(shape = (1024,1))\n",
        "\n",
        "  \n",
        "  capa1 = Conv1D(pNumFiltros[0], int(pTamFiltros[0]), padding='same', activation = 'sigmoid')(capaEntrada)\n",
        "  pooling1 = MaxPooling1D(int(pTamPooling[1]), padding='same')(capa1)\n",
        "\n",
        "  capa2 = Conv1D(pNumFiltros[1], int(pTamFiltros[1]), padding='same', activation = 'relu')(capa1)\n",
        "  pooling2 = MaxPooling1D(int(pTamPooling[2]), padding='same')(capa2)\n",
        "\n",
        "  capas = Flatten()(pooling2)\n",
        "  capas = Dropout(0.5)(capas)\n",
        "  \n",
        "  capas = Dense(pNumNeuronas[0], activation='relu')(capas)\n",
        "  capaSalida = Dense(3, activation='softmax')(capas)\n",
        "\n",
        "  modelo = Sequential()\n",
        "  modelo.add(Model(capaEntrada, capaSalida))\n",
        "\n",
        "  sgd = optimizers.SGD(lr = pTasa)#, momentum=0.9)\n",
        "  adam = optimizers.Adam(learning_rate = pTasa)\n",
        "  if pOptimizer == \"adam\":\n",
        "    opt=adam\n",
        "  elif pOptimizer ==\"sgd\":\n",
        "    opt=sgd\n",
        "  elif pOptimizer ==\"rmsprop\":\n",
        "    opt = \"rmsprop\"\n",
        "  \n",
        "  modelo.compile(loss='sparse_categorical_crossentropy', optimizer = opt, metrics = ['sparse_categorical_accuracy'])\n",
        "  modelo.layers[0].summary()\n",
        "  \n",
        "  return modelo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHkFvPP3aBEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Esta celda construye los modelos, a partir de los parametros especificados por cada una de las siguientes variables.\n",
        "\n",
        "#Es el numero de filtros que cada capa convolucional utiliza.\n",
        "numFiltros = np.array([10, 5, 100, 100, 100, 10])\n",
        "\n",
        "#Es el tamaño de los filtros utilizados en cada capa convolucional.\n",
        "tamFiltros = np.array([5, 4, 10, 8, 8, 5])\n",
        "\n",
        "#Es el tamaño de cada capa de Pooling.\n",
        "tamPooling = np.array([10, 10, 3, 3, 3, 3])\n",
        "\n",
        "#Es el numero de neuronas en cada capa de la red neuronal que sigue despues de la parte convolucional.\n",
        "numNeuronas = np.array([5, 10, 10])\n",
        "\n",
        "#Es el tipo de optimizador a utilizar.\n",
        "#Se pueden especificar: \"sgd\", \"adam\" o \"rmsprop\"\n",
        "optimizer=\"sgd\"\n",
        "\n",
        "#Es la tasa de aprendizaje del optimizador.\n",
        "tasa = 0.01\n",
        "\n",
        "#Es el parametro de regularizacion a utilizar.\n",
        "alpha = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ1gG_FRaVOi",
        "colab_type": "code",
        "outputId": "a0566d07-a9d3-43e9-e830-3412f1fb4708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "modelo1 = crearModelo(tasa, alpha, numFiltros, tamFiltros, tamPooling, numNeuronas, optimizer)\n",
        "\n",
        "#Esta linea muestra un diagrama de la red neuronal.\n",
        "SVG(model_to_dot(modelo1, show_shapes = True, expand_nested = True, dpi = 50).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1024, 1)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 1024, 10)          60        \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 1024, 5)           205       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 342, 5)            0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1710)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1710)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 5)                 8555      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 18        \n",
            "=================================================================\n",
            "Total params: 8,838\n",
            "Trainable params: 8,838\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"513pt\" viewBox=\"0.00 0.00 402.00 738.00\" width=\"279pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.6944 .6944) rotate(0) translate(4 734)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-734 398,-734 398,4 -4,4\" stroke=\"transparent\"/>\n<g class=\"cluster\" id=\"clust1\">\n<title>cluster_model_4</title>\n<polygon fill=\"none\" points=\"8,-8 8,-675 386,-675 386,-8 8,-8\" stroke=\"#000000\" stroke-dasharray=\"5,2\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"42\" y=\"-659.8\">model_4</text>\n</g>\n<!-- 140253183442224 -->\n<g class=\"node\" id=\"node1\">\n<title>140253183442224</title>\n<polygon fill=\"none\" points=\"33.5,-683.5 33.5,-729.5 360.5,-729.5 360.5,-683.5 33.5,-683.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121.5\" y=\"-702.8\">model_4_input: InputLayer</text>\n<polyline fill=\"none\" points=\"209.5,-683.5 209.5,-729.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-714.3\">input:</text>\n<polyline fill=\"none\" points=\"209.5,-706.5 267.5,-706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-691.3\">output:</text>\n<polyline fill=\"none\" points=\"267.5,-683.5 267.5,-729.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-714.3\">[(?, 1024, 1)]</text>\n<polyline fill=\"none\" points=\"267.5,-706.5 360.5,-706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-691.3\">[(?, 1024, 1)]</text>\n</g>\n<!-- 140253783134048 -->\n<g class=\"node\" id=\"node2\">\n<title>140253783134048</title>\n<polygon fill=\"none\" points=\"55,-597.5 55,-643.5 339,-643.5 339,-597.5 55,-597.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121.5\" y=\"-616.8\">input_5: InputLayer</text>\n<polyline fill=\"none\" points=\"188,-597.5 188,-643.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217\" y=\"-628.3\">input:</text>\n<polyline fill=\"none\" points=\"188,-620.5 246,-620.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217\" y=\"-605.3\">output:</text>\n<polyline fill=\"none\" points=\"246,-597.5 246,-643.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-628.3\">[(?, 1024, 1)]</text>\n<polyline fill=\"none\" points=\"246,-620.5 339,-620.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-605.3\">[(?, 1024, 1)]</text>\n</g>\n<!-- 140253183442224&#45;&gt;140253783134048 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140253183442224-&gt;140253783134048</title>\n<path d=\"M197,-683.4536C197,-674.2957 197,-663.5862 197,-653.6244\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"200.5001,-653.61 197,-643.61 193.5001,-653.6101 200.5001,-653.61\" stroke=\"#000000\"/>\n</g>\n<!-- 140254756923768 -->\n<g class=\"node\" id=\"node3\">\n<title>140254756923768</title>\n<polygon fill=\"none\" points=\"55.5,-514.5 55.5,-560.5 338.5,-560.5 338.5,-514.5 55.5,-514.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"122\" y=\"-533.8\">conv1d_8: Conv1D</text>\n<polyline fill=\"none\" points=\"188.5,-514.5 188.5,-560.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-545.3\">input:</text>\n<polyline fill=\"none\" points=\"188.5,-537.5 246.5,-537.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-522.3\">output:</text>\n<polyline fill=\"none\" points=\"246.5,-514.5 246.5,-560.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-545.3\">(?, 1024, 1)</text>\n<polyline fill=\"none\" points=\"246.5,-537.5 338.5,-537.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-522.3\">(?, 1024, 10)</text>\n</g>\n<!-- 140253783134048&#45;&gt;140254756923768 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140253783134048-&gt;140254756923768</title>\n<path d=\"M197,-597.3799C197,-589.1745 197,-579.7679 197,-570.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"200.5001,-570.784 197,-560.784 193.5001,-570.784 200.5001,-570.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140253468165008 -->\n<g class=\"node\" id=\"node4\">\n<title>140253468165008</title>\n<polygon fill=\"none\" points=\"55.5,-431.5 55.5,-477.5 338.5,-477.5 338.5,-431.5 55.5,-431.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"122\" y=\"-450.8\">conv1d_9: Conv1D</text>\n<polyline fill=\"none\" points=\"188.5,-431.5 188.5,-477.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-462.3\">input:</text>\n<polyline fill=\"none\" points=\"188.5,-454.5 246.5,-454.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-439.3\">output:</text>\n<polyline fill=\"none\" points=\"246.5,-431.5 246.5,-477.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-462.3\">(?, 1024, 10)</text>\n<polyline fill=\"none\" points=\"246.5,-454.5 338.5,-454.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-439.3\">(?, 1024, 5)</text>\n</g>\n<!-- 140254756923768&#45;&gt;140253468165008 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140254756923768-&gt;140253468165008</title>\n<path d=\"M197,-514.3799C197,-506.1745 197,-496.7679 197,-487.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"200.5001,-487.784 197,-477.784 193.5001,-487.784 200.5001,-487.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140253183522296 -->\n<g class=\"node\" id=\"node5\">\n<title>140253183522296</title>\n<polygon fill=\"none\" points=\"15.5,-348.5 15.5,-394.5 378.5,-394.5 378.5,-348.5 15.5,-348.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"126\" y=\"-367.8\">max_pooling1d_9: MaxPooling1D</text>\n<polyline fill=\"none\" points=\"236.5,-348.5 236.5,-394.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"265.5\" y=\"-379.3\">input:</text>\n<polyline fill=\"none\" points=\"236.5,-371.5 294.5,-371.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"265.5\" y=\"-356.3\">output:</text>\n<polyline fill=\"none\" points=\"294.5,-348.5 294.5,-394.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336.5\" y=\"-379.3\">(?, 1024, 5)</text>\n<polyline fill=\"none\" points=\"294.5,-371.5 378.5,-371.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336.5\" y=\"-356.3\">(?, 342, 5)</text>\n</g>\n<!-- 140253468165008&#45;&gt;140253183522296 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140253468165008-&gt;140253183522296</title>\n<path d=\"M197,-431.3799C197,-423.1745 197,-413.7679 197,-404.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"200.5001,-404.784 197,-394.784 193.5001,-404.784 200.5001,-404.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140253183508264 -->\n<g class=\"node\" id=\"node6\">\n<title>140253183508264</title>\n<polygon fill=\"none\" points=\"73,-265.5 73,-311.5 321,-311.5 321,-265.5 73,-265.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"129.5\" y=\"-284.8\">flatten_4: Flatten</text>\n<polyline fill=\"none\" points=\"186,-265.5 186,-311.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215\" y=\"-296.3\">input:</text>\n<polyline fill=\"none\" points=\"186,-288.5 244,-288.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215\" y=\"-273.3\">output:</text>\n<polyline fill=\"none\" points=\"244,-265.5 244,-311.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"282.5\" y=\"-296.3\">(?, 342, 5)</text>\n<polyline fill=\"none\" points=\"244,-288.5 321,-288.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"282.5\" y=\"-273.3\">(?, 1710)</text>\n</g>\n<!-- 140253183522296&#45;&gt;140253183508264 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140253183522296-&gt;140253183508264</title>\n<path d=\"M197,-348.3799C197,-340.1745 197,-330.7679 197,-321.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"200.5001,-321.784 197,-311.784 193.5001,-321.784 200.5001,-321.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140253462251728 -->\n<g class=\"node\" id=\"node7\">\n<title>140253462251728</title>\n<polygon fill=\"none\" points=\"66.5,-182.5 66.5,-228.5 327.5,-228.5 327.5,-182.5 66.5,-182.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.5\" y=\"-201.8\">dropout_3: Dropout</text>\n<polyline fill=\"none\" points=\"200.5,-182.5 200.5,-228.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-213.3\">input:</text>\n<polyline fill=\"none\" points=\"200.5,-205.5 258.5,-205.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-190.3\">output:</text>\n<polyline fill=\"none\" points=\"258.5,-182.5 258.5,-228.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293\" y=\"-213.3\">(?, 1710)</text>\n<polyline fill=\"none\" points=\"258.5,-205.5 327.5,-205.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293\" y=\"-190.3\">(?, 1710)</text>\n</g>\n<!-- 140253183508264&#45;&gt;140253462251728 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140253183508264-&gt;140253462251728</title>\n<path d=\"M197,-265.3799C197,-257.1745 197,-247.7679 197,-238.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"200.5001,-238.784 197,-228.784 193.5001,-238.784 200.5001,-238.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140253462251280 -->\n<g class=\"node\" id=\"node8\">\n<title>140253462251280</title>\n<polygon fill=\"none\" points=\"80,-99.5 80,-145.5 314,-145.5 314,-99.5 80,-99.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.5\" y=\"-118.8\">dense_8: Dense</text>\n<polyline fill=\"none\" points=\"187,-99.5 187,-145.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216\" y=\"-130.3\">input:</text>\n<polyline fill=\"none\" points=\"187,-122.5 245,-122.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216\" y=\"-107.3\">output:</text>\n<polyline fill=\"none\" points=\"245,-99.5 245,-145.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279.5\" y=\"-130.3\">(?, 1710)</text>\n<polyline fill=\"none\" points=\"245,-122.5 314,-122.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279.5\" y=\"-107.3\">(?, 5)</text>\n</g>\n<!-- 140253462251728&#45;&gt;140253462251280 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140253462251728-&gt;140253462251280</title>\n<path d=\"M197,-182.3799C197,-174.1745 197,-164.7679 197,-155.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"200.5001,-155.784 197,-145.784 193.5001,-155.784 200.5001,-155.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140253184081480 -->\n<g class=\"node\" id=\"node9\">\n<title>140253184081480</title>\n<polygon fill=\"none\" points=\"91,-16.5 91,-62.5 303,-62.5 303,-16.5 91,-16.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"144.5\" y=\"-35.8\">dense_9: Dense</text>\n<polyline fill=\"none\" points=\"198,-16.5 198,-62.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"227\" y=\"-47.3\">input:</text>\n<polyline fill=\"none\" points=\"198,-39.5 256,-39.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"227\" y=\"-24.3\">output:</text>\n<polyline fill=\"none\" points=\"256,-16.5 256,-62.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279.5\" y=\"-47.3\">(?, 5)</text>\n<polyline fill=\"none\" points=\"256,-39.5 303,-39.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279.5\" y=\"-24.3\">(?, 3)</text>\n</g>\n<!-- 140253462251280&#45;&gt;140253184081480 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140253462251280-&gt;140253184081480</title>\n<path d=\"M197,-99.3799C197,-91.1745 197,-81.7679 197,-72.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"200.5001,-72.784 197,-62.784 193.5001,-72.784 200.5001,-72.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og0JuJs6a_Xj",
        "colab_type": "code",
        "outputId": "4eb35499-31e8-491f-bd79-f3eeb7c03857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "epocas = 5\n",
        "batchSize = 1024\n",
        "\n",
        "modelo1.compile(loss='sparse_categorical_crossentropy', optimizer = optimizers.Adam(learning_rate = 0.001), metrics = ['sparse_categorical_accuracy'])\n",
        "\n",
        "for i in range(0,1):\n",
        "  #hist = modelo1.fit(x, y, verbose = 1, validation_data=(x, y), epochs = epocas, batch_size = batchSize)#, class_weight = pesosClases)\n",
        "  hist = modelo1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs = epocas, batch_size = batchSize)\n",
        "  \n",
        "                        \n",
        "\n",
        "  SVG(model_to_dot(modelo1, show_shapes = True, expand_nested = True, dpi = 60).create(prog='dot', format='svg'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 75219 samples, validate on 229326 samples\n",
            "Epoch 1/5\n",
            "75219/75219 [==============================] - 69s 917us/sample - loss: 1.1077 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.0950 - val_sparse_categorical_accuracy: 0.8906\n",
            "Epoch 2/5\n",
            "75219/75219 [==============================] - 69s 915us/sample - loss: 1.0986 - sparse_categorical_accuracy: 0.3324 - val_loss: 1.0979 - val_sparse_categorical_accuracy: 0.8906\n",
            "Epoch 3/5\n",
            "75219/75219 [==============================] - 69s 920us/sample - loss: 1.0986 - sparse_categorical_accuracy: 0.3318 - val_loss: 1.0977 - val_sparse_categorical_accuracy: 0.8906\n",
            "Epoch 4/5\n",
            "74752/75219 [============================>.] - ETA: 0s - loss: 1.0986 - sparse_categorical_accuracy: 0.3308"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-d49dd7b053d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#hist = modelo1.fit(x, y, verbose = 1, validation_data=(x, y), epochs = epocas, batch_size = batchSize)#, class_weight = pesosClases)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelo1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepocas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m           \u001b[0mvalidation_in_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m           \u001b[0mprepared_feed_values_from_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    441\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB_TZTe3LA9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZzT8SSv8nzk",
        "colab_type": "text"
      },
      "source": [
        "# Cargar y guardar modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK5RLFzj4hu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Estas funciones permiten guardar y cargar un modelo, a partir de las rutas indicadas por parametro.\n",
        "def guardarModelo(pModelo, pRutaModelo, pRutaPesos, pRutaDiagrama):\n",
        "  modelo_json = pModelo.to_json()\n",
        "\n",
        "  with open(pRutaModelo, \"w\") as archivo_json:\n",
        "      archivo_json.write(modelo_json)\n",
        "\n",
        "  pModelo.save_weights(pRutaPesos)\n",
        "\n",
        "  plot_model(pModelo, to_file = pRutaDiagrama, show_shapes = True)\n",
        "\n",
        "def cargarModelo(pRutaModelo, pRutaPesos):\n",
        "  archivo_json = open(pRutaModelo, 'r')\n",
        "  modelo_json = archivo_json.read()\n",
        "  archivo_json.close()\n",
        "  modelo = model_from_json(modelo_json)\n",
        "\n",
        "  modelo.load_weights(pRutaPesos)\n",
        "\n",
        "  return modelo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VxRH3Mb0TaM",
        "colab_type": "text"
      },
      "source": [
        "# Casti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyTYvB3LG3uZ",
        "colab_type": "code",
        "outputId": "fcb63913-54ab-409e-a558-624e56449071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# SVM\n",
        "# Ejemplo con datdabse de cancer para implementar un SVM\n",
        "from sklearn import datasets, svm, metrics, model_selection\n",
        "print('primera prueba SVM')\n",
        "\n",
        "cancer = datasets.load_breast_cancer()\n",
        "print(\"Features: \", cancer.feature_names)\n",
        "print(\"Labels: \", cancer.target_names)\n",
        "# Since our data is seperated by semicolons we need to do sep=\";\"\n",
        "\n",
        "x = cancer.data  # All of the features\n",
        "y = cancer.target  # All of the labels\n",
        "\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "clf = svm.SVC(kernel=\"linear\")\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(x_test)\n",
        "\n",
        "acc = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "primera prueba SVM\n",
            "Features:  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "Labels:  ['malignant' 'benign']\n",
            "0.9649122807017544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTcYiAOpzN8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# ignore warnings \n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "print('Necesito aprender a cargar datos a esta pagina !!')\n",
        "\n",
        "# Formas de extraer features\n",
        "###################### Entendiendo MFCC ##################\n",
        "# necesito agregar un path valido\n",
        "\n",
        "#mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
        "# Plots para entender lo que esta pasando\n",
        "# audio wave\n",
        "#plt.figure(figsize=(20, 15))\n",
        "#plt.subplot(3,1,1)\n",
        "#librosa.display.waveplot(X, sr=sample_rate)\n",
        "#plt.title('Audio sampled at 44100 hrz')\n",
        "\n",
        "# MFCC\n",
        "#plt.figure(figsize=(20, 15))\n",
        "#plt.subplot(3,1,1)\n",
        "#librosa.display.specshow(mfcc, x_axis='time')\n",
        "#plt.ylabel('MFCC')\n",
        "#plt.colorbar()\n",
        "\n",
        "#################### comparar 2 audios usando el MFCC ####################\n",
        "\n",
        "# Source - RAVDESS; Gender - Female; Emotion - Angry \n",
        "#path = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_08/03-01-05-02-01-01-08.wav\"\n",
        "#X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)  \n",
        "#female = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
        "#female = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
        "#print(len(female))\n",
        "\n",
        "# Source - RAVDESS; Gender - Male; Emotion - Angry \n",
        "#path = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_09/03-01-05-01-01-01-09.wav\"\n",
        "#X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)  \n",
        "#male = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
        "#male = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
        "#print(len(male))\n",
        "\n",
        "# audio wave\n",
        "#plt.figure(figsize=(20, 15))\n",
        "#plt.subplot(3,1,1)\n",
        "#plt.plot(female, label='female')\n",
        "#plt.plot(male, label='male')\n",
        "#plt.legend()\n",
        "\n",
        "#path = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_08/03-01-05-02-01-01-08.wav\"\n",
        "\n",
        "#Later on, during the accuracy improvement phase, we may expand our feature set to include Mel-Spectogram, Chroma, HPSS and etc... and not just a simple mean\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}