{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problema Especial Italiano.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfgf11/Problema-Especial/blob/master/Problema_Especial_Italiano.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtf-HdYxvLE9",
        "colab_type": "code",
        "outputId": "82adea0b-3046-4ce6-a8a9-2f345396182d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "#Se monta el Drive para importar y guardar los datos y modelos.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')#,force_remount = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKEEuc5e9DuD",
        "colab_type": "code",
        "outputId": "a566a925-beed-442c-effe-9d391fdeaccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Se instalan las librerias necesarias\n",
        "!pip install librosa\n",
        "!pip install progressbar2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.47.0)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.14.1)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.8)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.12.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (46.0.0)\n",
            "Requirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.31.0)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (3.38.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2) (2.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from progressbar2) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_goXBoAPsnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqWuMaqiELzW",
        "colab_type": "text"
      },
      "source": [
        "# Importar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV__vdiK4GUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tensor Flow\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import AveragePooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import SVG\n",
        "\n",
        "# Recopilacion de datos\n",
        "import xml.dom.minidom\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "\n",
        "# Para el preprocesamiento\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn import preprocessing\n",
        "from collections import Counter\n",
        "\n",
        "import librosa\n",
        "import progressbar\n",
        "\n",
        "\n",
        "# Import libraries \n",
        "import librosa.display\n",
        "from matplotlib.pyplot import specgram\n",
        "import pandas as pd\n",
        "import glob \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import IPython.display as ipd  # To play sound in the notebook\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "\n",
        "#Redes neuronales sklearn\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhIXgu2x18kP",
        "colab_type": "text"
      },
      "source": [
        "# Funciones Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HF9cm7zJN8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# De los creadores de EntrenamientoModelo*\n",
        "def graficarMatrizConfusion(y_true, y_pred):\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  \n",
        "\n",
        "  plt.figure(figsize=(8,8))\n",
        "\n",
        "  ax = sns.heatmap(cm, annot = True, cbar = False);\n",
        "      \n",
        "  ax.xaxis.tick_top()\n",
        "  ax.xaxis.set_label_position('top')\n",
        "      \n",
        "  plt.xlabel(\"Clase Prediccion\")\n",
        "  plt.ylabel(\"Clase Verdadera\")\n",
        "  plt.title(\"Matriz de Confusion\")\n",
        "\n",
        "  plt.show()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZzT8SSv8nzk",
        "colab_type": "text"
      },
      "source": [
        "# Cargar y guardar modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK5RLFzj4hu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# De los creadores de EntrenamientoModelo*\n",
        "#Estas funciones permiten guardar y cargar un modelo, a partir de las rutas indicadas por parametro.\n",
        "def guardarModelo(pModelo, pRutaModelo, pRutaPesos, pRutaDiagrama):\n",
        "  modelo_json = pModelo.to_json()\n",
        "\n",
        "  with open(pRutaModelo, \"w\") as archivo_json:\n",
        "      archivo_json.write(modelo_json)\n",
        "\n",
        "  pModelo.save_weights(pRutaPesos)\n",
        "\n",
        "  plot_model(pModelo, to_file = pRutaDiagrama, show_shapes = True)\n",
        "\n",
        "def cargarModelo(pRutaModelo, pRutaPesos):\n",
        "  archivo_json = open(pRutaModelo, 'r')\n",
        "  modelo_json = archivo_json.read()\n",
        "  archivo_json.close()\n",
        "  modelo = model_from_json(modelo_json)\n",
        "\n",
        "  modelo.load_weights(pRutaPesos)\n",
        "\n",
        "  return modelo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJf6aq0g378c",
        "colab_type": "text"
      },
      "source": [
        "Guardar modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21Qz9FD_kWFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Nombre = \"Jorge\"\n",
        "Numero = \"1\"\n",
        "#utaModelo = \"drive/My Drive/Proyecto Especial Italiano/Modelos/Modelos raw_Conv/Modelo_\"+Nombre+\"_\"+Numero+\".json\"\n",
        "#rutaPesos = \"drive/My Drive/Proyecto Especial Italiano/Modelos/Modelos raw_Conv/Pesos_Modelo_\"+Nombre+\"_\"+Numero+\".h5\"\n",
        "#rutaDiagrama = \"drive/My Drive/Proyecto Especial Italiano/Modelos/Modelos raw_Conv/Diagrama_Modelo_\"+Nombre+\"_\"+Numero+\".png\"\n",
        "\n",
        "#guardarModelo(modelo1, rutaModelo, rutaPesos, rutaDiagrama)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Saj0QSA3_eL",
        "colab_type": "text"
      },
      "source": [
        "Cargar Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYU5l-IiFdrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Nombre = \"Jorge\"\n",
        "Numero = \"1\"\n",
        "#rutaModelo = \"drive/My Drive/Proyecto Especial Italiano/Modelos/Modelos raw_Conv/Modelo_\"+Nombre+\"_\"+Numero+\".json\"\n",
        "#rutaPesos =  \"drive/My Drive/Proyecto Especial Italiano/Modelos/Modelos raw_Conv/Pesos_Modelo_\"+Nombre+\"_\"+Numero+\".h5\"\n",
        "#modelo1 = cargarModelo(pRutaModelo=rutaModelo, pRutaPesos=rutaPesos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hlwalP_JqiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#a = np.zeros(1280000000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLQEssmxVerC",
        "colab_type": "text"
      },
      "source": [
        "# Recopilación de Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwMARXzLvh-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ObtenerSonidos(Inicial_pNXML,   Final_pNXML,    Inicial_nAudios,               Final_nAudios,\n",
        "                  ventana_Tiempo=0.1,         salto_de_ventana=4,    Calcular_Features=False,       Sin_Background = False,\n",
        "                  rutaDatosXML=\"drive/My Drive/Proyecto Especial Italiano/MIVIA_DB4_dist/training\",\n",
        "                  rutaDatosSounds =\"drive/My Drive/Proyecto Especial Italiano/MIVIA_DB4_dist/training/sounds\", Solo_Background = False,\n",
        "                  sample_rate = 32000, MFCC = False, window_length_stft= 0.032, Step_size_stft=0.01, Espectogram = False ):\n",
        "\n",
        "\n",
        "  NMV = round(ventana_Tiempo*sample_rate) # Numero de muestras por ventana\n",
        "  NMV_advance = round(NMV/salto_de_ventana) # Numero de muestras por las cuales se avanza\n",
        "\n",
        "  if Calcular_Features: datos_x_totales=np.zeros((1,312)) \n",
        "  else: datos_x_totales=np.zeros((int(1280000000/NMV),NMV))\n",
        "  datos_y_totales=np.zeros(int(1280000000/NMV))\n",
        "  contador=0\n",
        "\n",
        "  with progressbar.ProgressBar(max_value=(Final_pNXML-Inicial_pNXML+1)*(Final_nAudios-Inicial_nAudios+1)) as bar:\n",
        "    longitud_actual = 0\n",
        "    for i in range(Inicial_pNXML_,(Final_pNXML_+1)):\n",
        "        \n",
        "        if i<10:  h=\"0\" # Se hace esto debido que en los audios hay elementos 00001_01 y 00010_1\n",
        "        else: h=\"\"\n",
        "\n",
        "        doc = xml.dom.minidom.parse(rutaDatosXML + \"/000\" + h + str(i) + \".xml\")\n",
        "        start = doc.getElementsByTagName(\"STARTSECOND\") #Vector que contiene el tiempo en segundos de inicio de todos los eventos \n",
        "        finish = doc.getElementsByTagName(\"ENDSECOND\") #Vector que contiene el tiempo en segundos de finalizacion de todos los eventos\n",
        "        ID = doc.getElementsByTagName(\"CLASS_ID\") # Vector que contiene la etiqueta de cada uno de los eventos\n",
        "        events = doc.getElementsByTagName(\"events\") # Indica informacion de todos los eventos en un archivo xml (tamaño)\n",
        "        a, b, c, d=(events[0].attributes[\"size\"].value) #Se obtiene el numero de eventos en un audio\n",
        "        nEventos = int(c+d) # numero de eventos en un audio\n",
        "\n",
        "\n",
        "        for a in range(Inicial_nAudios, (Final_nAudios)+1):# Numero de audios por xml\n",
        "          if a<2: # Se hace esto debido que en los audios hay elementos 00001_01 y 00010_1\n",
        "            r = \"0\"\n",
        "            t=str(a)\n",
        "          else:\n",
        "            t=str(a-1)\n",
        "            r=\"\"\n",
        "          frameData, fs = librosa.load(rutaDatosSounds + '/000' + h + str(i) +'_'+ r + t +'.wav', sr=sample_rate, res_type='kaiser_fast') #Audio seleccionado\n",
        "          datos_x = (librosa.util.frame(frameData, frame_length=NMV, hop_length=NMV_advance)).T # Reorganiza los datos dándole saltos de tiempo de NMV_advance y el número de muestras por ventana NMV\n",
        "          datos_y = np.zeros(len(frameData)) #Etiquetas de cada uno de los datos, los datos no asignados serán 0 y corresponderan a sonido ambiente\n",
        "\n",
        "          for j in range(0,nEventos): # Se recorre el numero de eventos para cada xml\n",
        "            startFrame = float(str(start[j].firstChild.data))*fs #Posicion inicial de evento con respecto a frameData\n",
        "            endFrame = float(str(finish[j].firstChild.data))*fs #Posicion final de evento con respecto a frameData\n",
        "            label = ID[j].firstChild.data #etiqueta del evento\n",
        "\n",
        "            datos_y[round(startFrame):round(endFrame)]=int(label) # Se asigna la etiqueta a cada uno de los datos recopilados\n",
        "\n",
        "          datos_y = (((stats.mode(librosa.util.frame(datos_y, frame_length=NMV, hop_length=NMV_advance)))[0]).T)# Con esto se asigna la etiqueta a datos desplazados en el tiempo\n",
        "          datos_y = np.reshape(datos_y, (-1), 'F')\n",
        "\n",
        "          if Sin_Background: # Si se quieren datos sin background\n",
        "            datos_x = datos_x[datos_y!=0,:]\n",
        "            datos_y =  datos_y[datos_y!=0]\n",
        "          \n",
        "          if Solo_Background:\n",
        "            datos_x = (datos_x[datos_y==0,:])[0:round(len(datos_y[datos_y==0])),:]\n",
        "            datos_y =  (datos_y[datos_y==0])[0:round(len(datos_y[datos_y==0]))]\n",
        "\n",
        "          longitud_siguiente = longitud_actual + len(datos_y)\n",
        "          datos_y_totales[longitud_actual:longitud_siguiente] = datos_y\n",
        "          datos_x_totales[longitud_actual:longitud_siguiente,:] = datos_x\n",
        "          longitud_actual = longitud_siguiente\n",
        "          \n",
        "\n",
        "          contador+=1\n",
        "          bar.update(contador) #Se actualiza la barra de progreso\n",
        "          \n",
        "    datos_x_totales = datos_x_totales[0:longitud_siguiente,:]\n",
        "    datos_y_totales = datos_y_totales[0:longitud_siguiente]\n",
        "\n",
        "    datos_y_totales[datos_y_totales==4] = 1\n",
        "    dato_x2_totales = None\n",
        "    if MFCC or Espectogram: # Se crea el Spectogram para cada dato\n",
        "      dato_x2_totales = Crear_Datos_MFCC_o_Espectogram(datos_x_totales ,fs, window_length_stft, Step_size_stft,MFCC, Espectogram)\n",
        "\n",
        "    \n",
        "  return datos_x_totales, dato_x2_totales ,datos_y_totales"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gITetZEsAM8B",
        "colab_type": "text"
      },
      "source": [
        "Datos Espectograma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo3wD4ALNroy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Crear_Datos_MFCC_o_Espectogram(pX,sr_, window_length_stft, Step_size_stft,MFCC, Espectogram):\n",
        "  contador=0\n",
        "  with progressbar.ProgressBar(max_value=(len(pX))) as bar:\n",
        "    if Espectogram:\n",
        "      if window_length_stft>=0.05 and window_length_stft>=0.025: ps = librosa.feature.melspectrogram(y=pX[0],  sr=sr_, n_fft = int(window_length_stft*sr_), hop_length = int(Step_size_stft*sr_))\n",
        "      else: ps = librosa.feature.melspectrogram(y=pX[0],  sr=sr_)\n",
        "    elif MFCC:\n",
        "      if window_length_stft>=0.05 and window_length_stft>=0.03125: ps = librosa.feature.mfcc(y=pX[0], sr=fs, n_mfcc=13, n_fft = int(window_length_stft*sr_), hop_length = int(Step_size_stft*sr_), htk=True )\n",
        "      else: ps = librosa.feature.mfcc(y=pX[0], sr=fs, n_mfcc=13)\n",
        "\n",
        "    x_2 = np.zeros((len(pX)+1,len(ps),len(ps[0])))\n",
        "    for i in range(0,len(pX)):\n",
        "      if Espectogram:\n",
        "        if window_length_stft>=0.05 and window_length_stft>=0.025: ps = librosa.feature.melspectrogram(y=pX[i],  sr=sr_, n_fft = int(window_length_stft*sr_), hop_length = int(Step_size_stft*sr_))\n",
        "        else: ps = librosa.feature.melspectrogram(y=pX[i],  sr=sr_)\n",
        "        ps = librosa.power_to_db(ps, ref=np.max)\n",
        "      elif MFCC:\n",
        "        if window_length_stft>=0.05 and window_length_stft>=0.03125: ps = librosa.feature.mfcc(y=pX[i], sr=fs, n_mfcc=13, n_fft = int(window_length_stft*sr_), hop_length = int(Step_size_stft*sr_), htk=True )\n",
        "        else: ps = librosa.feature.mfcc(y=pX[i], sr=fs, n_mfcc=13)\n",
        "      x_2[i] = ps\n",
        "      contador+=1\n",
        "      bar.update(contador) #Se actualiza la barra de progreso\n",
        "  x_2 = x_2[0:-1,:]\n",
        "  return x_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw8G-HTuEpRI",
        "colab_type": "text"
      },
      "source": [
        "Lo siguiente permite obtener los datos de sonido y guardarlos. Al final se obtiene y se guarda lo siguiente:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwAHvnGHnx-7",
        "colab_type": "text"
      },
      "source": [
        "x: Vector que contiene datos crudos de sonido pasados por una ventana de hammin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVRiIQomn0nI",
        "colab_type": "text"
      },
      "source": [
        "x2: Vector que contiene MFCC o Espectogramas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJuv8ztgn3iW",
        "colab_type": "text"
      },
      "source": [
        "y: Vector que contiene las etiquetas de todos los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INB19Yue-LQT",
        "colab_type": "code",
        "outputId": "7b122388-67a1-4529-8937-040e71d7e57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "ventana_Tiempo_ = 0.050 # La ventana de tiempo de cada muestra (XX_ms) \n",
        "ventana_Tiempo_String_ = \"050\" # La ventana de tiempo de cada muestra (XX_ms) \n",
        "salto_de_ventana_ = 4  # Corrimiento en tiempo (XXms/4)\n",
        "sample_rate_ = 16000 # Tasa remuestreo\n",
        "sample_rate_String = str(sample_rate_)\n",
        "# Si se está obteniendo el espectogramo, el valor de la ventana no puede ser menor a 0.025s\n",
        "# Si se está obteniendo el MFCC, el valor de la ventana no puede ser menor a 0.03125s\n",
        "window_length_stft_ = 0.025 # Ventana de tiempo para la short-Time Fourier Transform\n",
        "Step_size_stft_ = 0.010 # Saltos el en tiempo para la transformada de Fourier, fíjenlo menor a la ventana stft, si quieren pueden aumentar\n",
        "\n",
        "Sin_Background_ = False # True: no se obtienen datos de background; False: No se obtienen datos de background  NO MOVER\n",
        "Features_ = False # Obtener o no features NO MOVER\n",
        "Inicial_pNXML_ = 1 # Número inicial de archivos XML utilizados  NO MOVER, a menos de que se quiera obtener 45 a 55\n",
        "Final_pNXML_ = 10 # Número final de archivos XML utilizados  NO MOVER, a menos de que se quiera obtener 45 a 55\n",
        "Inicial_nAudios_ = 0 # Número inicial de audios que se obtendrán (esto no aplica para nuestros audios)  NO MOVER\n",
        "Final_nAudios_ = 7 # Número final de audios que se obtendrán (esto no aplica para nuestros audios)  NO MOVER\n",
        "rutaDatosXML_ = \"drive/My Drive/Proyecto Especial Italiano/MIVIA_DB4_dist/training\" #Ruta para encontrar archivos xml  NO MOVER\n",
        "rutaDatosSounds_ = \"drive/My Drive/Proyecto Especial Italiano/MIVIA_DB4_dist/training/sounds\"  #Ruta para encontrar Audios  NO MOVER\n",
        "Solo_Background_ = False #Solo obtener datos de background  NO MOVER\n",
        "Nombre = \"Jorge\" ## PONER NOMBRE QUIEN REALIZA LA PRUEBA\n",
        "#a,b,c,d,e=str(ventana_Tiempo_)\n",
        "\n",
        "\n",
        "# Si ambos son True, se obtendrá únicamente el espectogram\n",
        "Espectogram_ = True #Calcular el espectograma\n",
        "MFCC_ = False #Calcular a su vez el MFCC  \n",
        "\n",
        "\n",
        "x, x2, y =ObtenerSonidos(Inicial_pNXML = Inicial_pNXML_, Final_pNXML = Final_pNXML_,     Inicial_nAudios = Inicial_nAudios_,\n",
        "                    Final_nAudios = Final_nAudios_,  ventana_Tiempo=ventana_Tiempo_, salto_de_ventana=salto_de_ventana_, \n",
        "                    Calcular_Features=Features_,        Sin_Background =Sin_Background_, \n",
        "                    rutaDatosXML = rutaDatosXML_,   rutaDatosSounds=rutaDatosSounds_, Solo_Background = Solo_Background_, \n",
        "                    sample_rate=sample_rate_,        MFCC=MFCC_, window_length_stft= window_length_stft_, Step_size_stft=Step_size_stft_\n",
        "                    ,Espectogram = Espectogram_)\n",
        "\n",
        "if Sin_Background_: Back = \"_SIN_BACK\"\n",
        "elif Solo_Background_: Back = \"_SOLO_BACK\"\n",
        "else: Back = \"\"\n",
        "if Features_: Features_or_raw = \" Features\"\n",
        "else: Features_or_raw = \" raw_Conv\"\n",
        "\n",
        "if Espectogram_: Esp_o_Mfcc = \"Spectopgram\"\n",
        "elif MFCC_:Esp_o_Mfcc = \"MFCC\"\n",
        "else: Esp_o_Mfcc = \"\"\n",
        "\n",
        "if MFCC_ or Espectogram_:\n",
        "  np.save(\"drive/My Drive/Proyecto Especial Italiano/Datos Procesados/Datos\" + Features_or_raw +\"/x2_\"+str(Inicial_pNXML_)+\"-\"\n",
        "       + str(Final_pNXML_)+ \"_XML_\"+str(Inicial_nAudios_)+\"-\"+ str(Final_nAudios_) +\"_Audios_\"+ventana_Tiempo_String_+\"s_\"+ sample_rate_String + \"_\"+Nombre+  Back+ \"_\" \n",
        "       + Esp_o_Mfcc , x2)\n",
        "x2 = [] #Para poder guardar se deben eliminar los datos x2, esto puesto que los datos x se pasaran por una ventana de hammin\n",
        "NMV = round(ventana_Tiempo_*sample_rate_) # Numero de muestras por ventana\n",
        "window = np.hamming(NMV) # se crea la ventana de hamming\n",
        "x = x*window #Se pasa cada uno de los datos por una ventana de hamming\n",
        "\n",
        "np.save(\"drive/My Drive/Proyecto Especial Italiano/Datos Procesados/Datos\" + Features_or_raw +\"/x_\"+str(Inicial_pNXML_)+\"-\"\n",
        "        + str(Final_pNXML_)+ \"_XML_\"+str(Inicial_nAudios_)+\"-\"+ str(Final_nAudios_) +\"_Audios_\"+ventana_Tiempo_String_+\"s_\"+sample_rate_String + \"_\"+Nombre +Back, x)\n",
        "np.save(\"drive/My Drive/Proyecto Especial Italiano/Datos Procesados/Datos\" + Features_or_raw +\"/y_\"+str(Inicial_pNXML_)+\"-\"\n",
        "        + str(Final_pNXML_)+ \"_XML_\"+str(Inicial_nAudios_)+\"-\"+ str(Final_nAudios_) +\"_Audios_\"+ventana_Tiempo_String_+\"s_\"+sample_rate_String + \"_\" + Nombre  + Back, y)\n",
        "print(\"Se acabo\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (1174056 of 1174056) |##############| Elapsed Time: 1:29:15 Time:  1:29:15\n",
            "100% (80 of 80) |########################| Elapsed Time: 1:33:32 Time:  1:33:32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Se acabo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leHL4EhjsoqB",
        "colab_type": "text"
      },
      "source": [
        "El objetivo de la siguiente función es acoplar los datos de los descriptores o de los datos raw obtenidos en un solo vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlXJ9xvrWOvH",
        "colab_type": "text"
      },
      "source": [
        "# Preprocesamiento de los datos\n",
        "Aquí se debe realizar todo el preprocesamiento de los datos. Se debe considerar el desbalance en los datos de entrenamiento. Primero se separan los datos de entrenamiento y validación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgWAcY2YVhvk",
        "colab_type": "text"
      },
      "source": [
        "Se extraen los datos guardados:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy0LM1NK4cv-",
        "colab_type": "text"
      },
      "source": [
        "Extraer datos específicos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHZbEBZwOf79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Numero = \"200\"\n",
        "Nombre = \"Male\"\n",
        "Esp_o_Mfcc = \"Spectopgram\"\n",
        "sample_rate_String = \"16000\"\n",
        "x = np.load(\"drive/My Drive/Proyecto Especial Italiano/Datos Procesados/Datos raw_Conv/x_1-10_XML_0-7_Audios_\"+Numero+\"s_\"+sample_rate_String + \"_\"+Nombre+\".npy\")\n",
        "x2 = np.load(\"drive/My Drive/Proyecto Especial Italiano/Datos Procesados/Datos raw_Conv/x2_1-10_XML_0-7_Audios_\"+Numero+\"s_\"+sample_rate_String + \"_\"+Nombre+\"_\"+Esp_o_Mfcc+\".npy\")\n",
        "y = np.load(\"drive/My Drive/Proyecto Especial Italiano/Datos Procesados/Datos raw_Conv/y_1-10_XML_0-7_Audios_\"+Numero+\"s_\"+sample_rate_String + \"_\"+Nombre+\".npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THQZW9ue5tmx",
        "colab_type": "code",
        "outputId": "aae0374e-6a71-4e80-dfb1-7b2ebd67d7d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(293312,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae2TIwGBBo5A",
        "colab_type": "text"
      },
      "source": [
        "La siguiente celda permite dividir los datos en datos de entrenamiento y datos de validación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1OKZiZQVnUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_1, x_test_1, y_train, y_test = train_test_split(x, y , random_state = 0, test_size=0.20)\n",
        "x=[]\n",
        "x_train_2, x_test_2, y_train, y_test = train_test_split(x2, y, random_state = 0, test_size=0.20)\n",
        "x2 = []\n",
        "y=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puzIWlNSbH4n",
        "colab_type": "text"
      },
      "source": [
        "A continuación se muestra el número de datos de cada etiqueta para datos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zobiHSMjhnVo",
        "colab_type": "code",
        "outputId": "d993cea3-6531-4e79-bc79-903a9e30b5c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Original dataset shape %s' % Counter(y_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original dataset shape Counter({0.0: 190414, 1.0: 19212, 2.0: 18548, 3.0: 6475})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSkN6slhzwjn",
        "colab_type": "text"
      },
      "source": [
        "Si se desean realizar pruebas sin datos de background ejecutar el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AzfRWG0CT8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x_train=x_train[y_train!=0]\n",
        "#y_train=y_train[y_train!=0]\n",
        "#x_test=x_test[y_test!=1]\n",
        "#y_test=y_test[y_test!=1]\n",
        "#y_test[y_test==1]=0\n",
        "#y_test[y_test==2]=1\n",
        "#y_test[y_test==3]=2\n",
        "#y_train[y_train==1]=0\n",
        "#y_train[y_train==2]=1\n",
        "#y_train[y_train==3]=2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXoqbJrtYEPC",
        "colab_type": "text"
      },
      "source": [
        "Random under Sampling\n",
        "\n",
        "Esto quita datos en exceso pero como hay muy pocos de gunshot si no se maneja bien no va tener sentido utilizarlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erkI7P6UWdCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Numero_Datos, alto_1, ancho_1=x_train_1.shape\n",
        "Numero_Datos, alto_2, ancho_2=x_train_2.shape\n",
        "\n",
        "#x_train_1 = np.reshape(x_train_1, (-1, 1600), 'F')\n",
        "x_train_2 = np.reshape(x_train_2, (-1, alto_2*ancho_2), 'F')\n",
        "\n",
        "print('Original dataset shape %s' % Counter(y_train))\n",
        "\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "x_train_1, l = rus.fit_resample(x_train_1, y_train)\n",
        "l=[]\n",
        "x_train_2, y_train = rus.fit_resample(x_train_2, y_train)\n",
        "\n",
        "print('Resampled dataset shape %s' % Counter(y_train))\n",
        "\n",
        "#x_train_1 = np.reshape(x_train_1, (-1, 1600), 'F')\n",
        "x_train_2 = np.reshape(x_train_2, (-1, alto_2, ancho_2), 'F')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV9GnndmcxxW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Random Over Sampler.\n",
        "\n",
        "\n",
        "Esto va a hacer que todo colapse si hay muchos datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZv1PirZcxP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Numero_Datos, alto_1, ancho_1=x_train_1.shape\n",
        "Numero_Datos, alto_2, ancho_2=x_train_2.shape\n",
        "\n",
        "#x_train_1 = np.reshape(x_train_1, (-1, 1600), 'F')\n",
        "x_train_2 = np.reshape(x_train_2, (-1, alto_2*ancho_2), 'F')\n",
        "\n",
        "print('Original dataset shape %s' % Counter(y_train_))\n",
        "print(\"Oversampling...\")\n",
        "\n",
        "randomOverSampler = RandomOverSampler(sampling_strategy = 'not majority', random_state = 0)\n",
        "x_train_1, l = randomOverSampler.fit_resample(x_train_1, y_train)\n",
        "l=[]\n",
        "x_train_2, y_train = randomOverSampler.fit_resample(x_train_2, y_train)\n",
        "\n",
        "\n",
        "print(\"Reshaping...\")\n",
        "print('Resampled dataset shape %s' % Counter(y_train_))\n",
        "\n",
        "#x_train_1 = np.reshape(x_train_1, (-1, 1600), 'F')\n",
        "x_train_2 = np.reshape(x_train_2, (-1, alto_2, ancho_2), 'F')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Sx-tobDCui",
        "colab_type": "text"
      },
      "source": [
        "Si se utiliza Keras, se debe correr la siguiente celda por el formato de como deben estar los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-YNTQpwZ80L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alto_1, ancho_1=x_train_1.shape\n",
        "Numero_Datos, alto_2, ancho_2=x_train_2.shape\n",
        "x_train_1 = np.reshape(x_train_1, (-1, ancho_1, 1), 'F')\n",
        "x_test_1 = np.reshape(x_test_1, (-1, ancho_1, 1), 'F')\n",
        "x_train_2 = np.reshape(x_train_2, (-1,1, alto_2, ancho_2), 'F')\n",
        "x_test_2 = np.reshape(x_test_2, (-1,1, alto_2, ancho_2), 'F')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTJNaRepVFKw",
        "colab_type": "text"
      },
      "source": [
        "En esta celda se calculan los pesos de cada clase, a partir de la cantidad de cada una en los datos de entrenamiento.Estos pesos también pueden ser variados manualmente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjS9Cr4GVD_F",
        "colab_type": "code",
        "outputId": "2bcdb843-e622-47d1-a935-e5d8e19a6b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pesosClases = compute_class_weight(class_weight = 'balanced', classes = np.array([0, 1, 2,3]), y = y_train)\n",
        "PesosClases = {0: pesosClases[0]*0.0001,\n",
        "               1: pesosClases[1]+10,\n",
        "               2: pesosClases[2]+10,\n",
        "               3: pesosClases[3]+30}\n",
        "print(PesosClases)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 3.080773997710252e-05, 1: 13.053417135123881, 2: 13.162726439508303, 3: 39.05980694980695}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MuYTEDh0F-i",
        "colab_type": "text"
      },
      "source": [
        "# Entrenamiento con diferentes Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiQv5-M_HV7X",
        "colab_type": "text"
      },
      "source": [
        "# Modelos Convolucionales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxisMR-rIPke",
        "colab_type": "text"
      },
      "source": [
        "Trabajo a futuro, agregar parámetros de regularización..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks2p-3735N0-",
        "colab_type": "text"
      },
      "source": [
        "# Modelo CNN 1D\n",
        "Las siguientes tres celdas de código crean el modelo. La cuarta celda empieza el entrenamiento. La quinta grafica la matriz de confusión, si no funciona se debe correr la función de matriz de confusión que está en la sección Funciones Resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb67wNlZcjIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crearModelo_1D(pTasa, pAlpha, pNumFiltros, pTamFiltros, pTamPooling, pNumNeuronas, pOptimizer, T_entrada):\n",
        "\n",
        "  modelo = Sequential()\n",
        "\n",
        "  modelo.add(Input(shape = (T_entrada,1)))\n",
        "\n",
        "  modelo.add(Conv1D(pNumFiltros[0], (int(pTamFiltros[0])), padding='same', activation = 'relu'))\n",
        "  modelo.add(Conv1D(pNumFiltros[1], (int(pTamFiltros[1])), padding='same', activation = 'relu'))\n",
        " \n",
        "  modelo.add(Conv1D(pNumFiltros[2], (int(pTamFiltros[2])), padding='same', activation = 'relu'))\n",
        "  #modelo.add(Conv1D(pNumFiltros[3], (int(pTamFiltros[3])), padding='same', activation = 'relu'))\n",
        "\n",
        "  modelo.add(MaxPooling1D((int(pTamFiltros[0])), padding='same'))\n",
        "\n",
        "\n",
        "  modelo.add(Dropout(0.5))\n",
        "  modelo.add(Flatten())\n",
        "\n",
        "  modelo.add(Dense(pNumNeuronas[0], activation='relu'))\n",
        "  modelo.add(Dense(pNumNeuronas[1], activation='relu'))\n",
        "\n",
        "  modelo.add(Dense(4, activation='softmax'))\n",
        "\n",
        "\n",
        "  sgd = optimizers.SGD(lr = pTasa)#, momentum=0.9)\n",
        "  adam = optimizers.Adam(learning_rate = pTasa)\n",
        "  if pOptimizer == \"adam\":\n",
        "    opt=adam\n",
        "  elif pOptimizer ==\"sgd\":\n",
        "    opt=sgd\n",
        "  elif pOptimizer ==\"rmsprop\":\n",
        "    opt = \"rmsprop\"\n",
        "  \n",
        "  modelo.compile(loss='sparse_categorical_crossentropy', optimizer = opt, metrics = ['sparse_categorical_accuracy'])\n",
        "  modelo.summary()\n",
        "  \n",
        "  return modelo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHkFvPP3aBEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Esta define los parametros especificados por cada una de las siguientes variables.\n",
        "#Es el numero de filtros que cada capa convolucional utiliza.\n",
        "numFiltros = np.array([5, 5, 5, 100, 100, 10])\n",
        "\n",
        "#Es el tamaño de los filtros utilizados en cada capa convolucional.\n",
        "tamFiltros = np.array([10, 10, 5, 8, 8, 5])\n",
        "\n",
        "#Es el tamaño de cada capa de Pooling.\n",
        "tamPooling = np.array([4, 2, 3, 3, 3, 3])\n",
        "\n",
        "#Es el numero de neuronas en cada capa de la red neuronal que sigue despues de la parte convolucional.\n",
        "numNeuronas = np.array([10, 10, 10])\n",
        "\n",
        "#Es el tipo de optimizador a utilizar.\n",
        "#Se pueden especificar: \"sgd\", \"adam\" o \"rmsprop\"\n",
        "optimizer=\"rmsprop\"\n",
        "\n",
        "#Es la tasa de aprendizaje del optimizador.\n",
        "tasa = 0.1\n",
        "\n",
        "#Es el parametro de regularizacion a utilizar.\n",
        "alpha = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ1gG_FRaVOi",
        "colab_type": "code",
        "outputId": "12d12f0e-a5f3-46b1-cd99-65360dee9889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Numero_Datos, ancho_1, alto_1, =x_train_1.shape\n",
        "\n",
        "modelo1 = crearModelo_1D(tasa, alpha, numFiltros, tamFiltros, tamPooling, numNeuronas, optimizer, T_entrada = ancho_1)\n",
        "\n",
        "#Esta linea muestra un diagrama de la red neuronal.\n",
        "SVG(model_to_dot(modelo1, show_shapes = True, expand_nested = True, dpi = 50).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 3200, 5)           55        \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 3200, 5)           255       \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 3200, 5)           130       \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 320, 5)            0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 320, 5)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                16010     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 44        \n",
            "=================================================================\n",
            "Total params: 16,604\n",
            "Trainable params: 16,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"557pt\" viewBox=\"0.00 0.00 356.00 802.00\" width=\"247pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.6944 .6944) rotate(0) translate(4 798)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-798 352,-798 352,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140257799416464 -->\n<g class=\"node\" id=\"node1\">\n<title>140257799416464</title>\n<polygon fill=\"none\" points=\"32,-747.5 32,-793.5 316,-793.5 316,-747.5 32,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.5\" y=\"-766.8\">input_1: InputLayer</text>\n<polyline fill=\"none\" points=\"165,-747.5 165,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"165,-770.5 223,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"223,-747.5 223,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269.5\" y=\"-778.3\">[(?, 3200, 1)]</text>\n<polyline fill=\"none\" points=\"223,-770.5 316,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269.5\" y=\"-755.3\">[(?, 3200, 1)]</text>\n</g>\n<!-- 140257799416128 -->\n<g class=\"node\" id=\"node2\">\n<title>140257799416128</title>\n<polygon fill=\"none\" points=\"44,-664.5 44,-710.5 304,-710.5 304,-664.5 44,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-683.8\">conv1d: Conv1D</text>\n<polyline fill=\"none\" points=\"162,-664.5 162,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"162,-687.5 220,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"220,-664.5 220,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-695.3\">(?, 3200, 1)</text>\n<polyline fill=\"none\" points=\"220,-687.5 304,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-672.3\">(?, 3200, 5)</text>\n</g>\n<!-- 140257799416464&#45;&gt;140257799416128 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140257799416464-&gt;140257799416128</title>\n<path d=\"M174,-747.3799C174,-739.1745 174,-729.7679 174,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"177.5001,-720.784 174,-710.784 170.5001,-720.784 177.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140257790650688 -->\n<g class=\"node\" id=\"node3\">\n<title>140257790650688</title>\n<polygon fill=\"none\" points=\"36.5,-581.5 36.5,-627.5 311.5,-627.5 311.5,-581.5 36.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-600.8\">conv1d_1: Conv1D</text>\n<polyline fill=\"none\" points=\"169.5,-581.5 169.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"169.5,-604.5 227.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"227.5,-581.5 227.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269.5\" y=\"-612.3\">(?, 3200, 5)</text>\n<polyline fill=\"none\" points=\"227.5,-604.5 311.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269.5\" y=\"-589.3\">(?, 3200, 5)</text>\n</g>\n<!-- 140257799416128&#45;&gt;140257790650688 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140257799416128-&gt;140257790650688</title>\n<path d=\"M174,-664.3799C174,-656.1745 174,-646.7679 174,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"177.5001,-637.784 174,-627.784 170.5001,-637.784 177.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140257790880176 -->\n<g class=\"node\" id=\"node4\">\n<title>140257790880176</title>\n<polygon fill=\"none\" points=\"36.5,-498.5 36.5,-544.5 311.5,-544.5 311.5,-498.5 36.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-517.8\">conv1d_2: Conv1D</text>\n<polyline fill=\"none\" points=\"169.5,-498.5 169.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"169.5,-521.5 227.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"227.5,-498.5 227.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269.5\" y=\"-529.3\">(?, 3200, 5)</text>\n<polyline fill=\"none\" points=\"227.5,-521.5 311.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269.5\" y=\"-506.3\">(?, 3200, 5)</text>\n</g>\n<!-- 140257790650688&#45;&gt;140257790880176 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140257790650688-&gt;140257790880176</title>\n<path d=\"M174,-581.3799C174,-573.1745 174,-563.7679 174,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"177.5001,-554.784 174,-544.784 170.5001,-554.784 177.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140257790430960 -->\n<g class=\"node\" id=\"node5\">\n<title>140257790430960</title>\n<polygon fill=\"none\" points=\"0,-415.5 0,-461.5 348,-461.5 348,-415.5 0,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-434.8\">max_pooling1d: MaxPooling1D</text>\n<polyline fill=\"none\" points=\"206,-415.5 206,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"206,-438.5 264,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"264,-415.5 264,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"306\" y=\"-446.3\">(?, 3200, 5)</text>\n<polyline fill=\"none\" points=\"264,-438.5 348,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"306\" y=\"-423.3\">(?, 320, 5)</text>\n</g>\n<!-- 140257790880176&#45;&gt;140257790430960 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140257790880176-&gt;140257790430960</title>\n<path d=\"M174,-498.3799C174,-490.1745 174,-480.7679 174,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"177.5001,-471.784 174,-461.784 170.5001,-471.784 177.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140257790879784 -->\n<g class=\"node\" id=\"node6\">\n<title>140257790879784</title>\n<polygon fill=\"none\" points=\"47,-332.5 47,-378.5 301,-378.5 301,-332.5 47,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"106.5\" y=\"-351.8\">dropout: Dropout</text>\n<polyline fill=\"none\" points=\"166,-332.5 166,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"166,-355.5 224,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"224,-332.5 224,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262.5\" y=\"-363.3\">(?, 320, 5)</text>\n<polyline fill=\"none\" points=\"224,-355.5 301,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262.5\" y=\"-340.3\">(?, 320, 5)</text>\n</g>\n<!-- 140257790430960&#45;&gt;140257790879784 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140257790430960-&gt;140257790879784</title>\n<path d=\"M174,-415.3799C174,-407.1745 174,-397.7679 174,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"177.5001,-388.784 174,-378.784 170.5001,-388.784 177.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140257790452064 -->\n<g class=\"node\" id=\"node7\">\n<title>140257790452064</title>\n<polygon fill=\"none\" points=\"57.5,-249.5 57.5,-295.5 290.5,-295.5 290.5,-249.5 57.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"106.5\" y=\"-268.8\">flatten: Flatten</text>\n<polyline fill=\"none\" points=\"155.5,-249.5 155.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"155.5,-272.5 213.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"213.5,-249.5 213.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"252\" y=\"-280.3\">(?, 320, 5)</text>\n<polyline fill=\"none\" points=\"213.5,-272.5 290.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"252\" y=\"-257.3\">(?, 1600)</text>\n</g>\n<!-- 140257790879784&#45;&gt;140257790452064 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140257790879784-&gt;140257790452064</title>\n<path d=\"M174,-332.3799C174,-324.1745 174,-314.7679 174,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"177.5001,-305.784 174,-295.784 170.5001,-305.784 177.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140257790430904 -->\n<g class=\"node\" id=\"node8\">\n<title>140257790430904</title>\n<polygon fill=\"none\" points=\"64.5,-166.5 64.5,-212.5 283.5,-212.5 283.5,-166.5 64.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-185.8\">dense: Dense</text>\n<polyline fill=\"none\" points=\"156.5,-166.5 156.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"156.5,-189.5 214.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"214.5,-166.5 214.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249\" y=\"-197.3\">(?, 1600)</text>\n<polyline fill=\"none\" points=\"214.5,-189.5 283.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249\" y=\"-174.3\">(?, 10)</text>\n</g>\n<!-- 140257790452064&#45;&gt;140257790430904 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140257790452064-&gt;140257790430904</title>\n<path d=\"M174,-249.3799C174,-241.1745 174,-231.7679 174,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"177.5001,-222.784 174,-212.784 170.5001,-222.784 177.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140257790430848 -->\n<g class=\"node\" id=\"node9\">\n<title>140257790430848</title>\n<polygon fill=\"none\" points=\"64.5,-83.5 64.5,-129.5 283.5,-129.5 283.5,-83.5 64.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118\" y=\"-102.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"171.5,-83.5 171.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"171.5,-106.5 229.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"229.5,-83.5 229.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-114.3\">(?, 10)</text>\n<polyline fill=\"none\" points=\"229.5,-106.5 283.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-91.3\">(?, 10)</text>\n</g>\n<!-- 140257790430904&#45;&gt;140257790430848 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140257790430904-&gt;140257790430848</title>\n<path d=\"M174,-166.3799C174,-158.1745 174,-148.7679 174,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"177.5001,-139.784 174,-129.784 170.5001,-139.784 177.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140257790452848 -->\n<g class=\"node\" id=\"node10\">\n<title>140257790452848</title>\n<polygon fill=\"none\" points=\"64.5,-.5 64.5,-46.5 283.5,-46.5 283.5,-.5 64.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"171.5,-.5 171.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"171.5,-23.5 229.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"229.5,-.5 229.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-31.3\">(?, 10)</text>\n<polyline fill=\"none\" points=\"229.5,-23.5 283.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-8.3\">(?, 4)</text>\n</g>\n<!-- 140257790430848&#45;&gt;140257790452848 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140257790430848-&gt;140257790452848</title>\n<path d=\"M174,-83.3799C174,-75.1745 174,-65.7679 174,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"177.5001,-56.784 174,-46.784 170.5001,-56.784 177.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og0JuJs6a_Xj",
        "colab_type": "code",
        "outputId": "c57eafc5-12f8-4dac-e64d-8edc9fb10fe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epocas = 100\n",
        "batchSize = 5000\n",
        "\n",
        "#modelo1.compile(loss='sparse_categorical_crossentropy', optimizer = \"rmsprop\", metrics = ['sparse_categorical_accuracy'])\n",
        "\n",
        "for i in range(0,1):\n",
        "  hist = modelo1.fit(x_train_1, y_train, validation_data=(x_test_1, y_test), epochs = epocas, batch_size = batchSize, class_weight = pesosClases)\n",
        " \n",
        "                        \n",
        "\n",
        "  #SVG(model_to_dot(modelo1, show_shapes = True, expand_nested = True, dpi = 60).create(prog='dot', format='svg'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 234649 samples, validate on 58663 samples\n",
            "Epoch 1/100\n",
            "234649/234649 [==============================] - 13s 56us/sample - loss: 0.8330 - sparse_categorical_accuracy: 0.7958 - val_loss: 0.6719 - val_sparse_categorical_accuracy: 0.8108\n",
            "Epoch 2/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.6214 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5692 - val_sparse_categorical_accuracy: 0.8199\n",
            "Epoch 3/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.5482 - sparse_categorical_accuracy: 0.8231 - val_loss: 0.5235 - val_sparse_categorical_accuracy: 0.8290\n",
            "Epoch 4/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.5191 - sparse_categorical_accuracy: 0.8323 - val_loss: 0.5132 - val_sparse_categorical_accuracy: 0.8368\n",
            "Epoch 5/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.4981 - sparse_categorical_accuracy: 0.8381 - val_loss: 0.4935 - val_sparse_categorical_accuracy: 0.8385\n",
            "Epoch 6/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.4778 - sparse_categorical_accuracy: 0.8435 - val_loss: 0.4553 - val_sparse_categorical_accuracy: 0.8502\n",
            "Epoch 7/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.4553 - sparse_categorical_accuracy: 0.8562 - val_loss: 0.4488 - val_sparse_categorical_accuracy: 0.8582\n",
            "Epoch 8/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.4315 - sparse_categorical_accuracy: 0.8668 - val_loss: 0.4179 - val_sparse_categorical_accuracy: 0.8752\n",
            "Epoch 9/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.4089 - sparse_categorical_accuracy: 0.8736 - val_loss: 0.3854 - val_sparse_categorical_accuracy: 0.8772\n",
            "Epoch 10/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.3898 - sparse_categorical_accuracy: 0.8781 - val_loss: 0.3678 - val_sparse_categorical_accuracy: 0.8842\n",
            "Epoch 11/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.3743 - sparse_categorical_accuracy: 0.8821 - val_loss: 0.3787 - val_sparse_categorical_accuracy: 0.8821\n",
            "Epoch 12/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.3629 - sparse_categorical_accuracy: 0.8860 - val_loss: 0.3480 - val_sparse_categorical_accuracy: 0.8883\n",
            "Epoch 13/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.3535 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.3331 - val_sparse_categorical_accuracy: 0.8917\n",
            "Epoch 14/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.3430 - sparse_categorical_accuracy: 0.8913 - val_loss: 0.3427 - val_sparse_categorical_accuracy: 0.8930\n",
            "Epoch 15/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.3371 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.3159 - val_sparse_categorical_accuracy: 0.8993\n",
            "Epoch 16/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.3294 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.3347 - val_sparse_categorical_accuracy: 0.8933\n",
            "Epoch 17/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.3239 - sparse_categorical_accuracy: 0.8972 - val_loss: 0.3064 - val_sparse_categorical_accuracy: 0.9038\n",
            "Epoch 18/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.3200 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.3213 - val_sparse_categorical_accuracy: 0.8971\n",
            "Epoch 19/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.3132 - sparse_categorical_accuracy: 0.9008 - val_loss: 0.3048 - val_sparse_categorical_accuracy: 0.9058\n",
            "Epoch 20/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.3088 - sparse_categorical_accuracy: 0.9033 - val_loss: 0.3169 - val_sparse_categorical_accuracy: 0.9017\n",
            "Epoch 21/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.3046 - sparse_categorical_accuracy: 0.9041 - val_loss: 0.2840 - val_sparse_categorical_accuracy: 0.9091\n",
            "Epoch 22/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.3010 - sparse_categorical_accuracy: 0.9056 - val_loss: 0.2807 - val_sparse_categorical_accuracy: 0.9108\n",
            "Epoch 23/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2976 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.2932 - val_sparse_categorical_accuracy: 0.9118\n",
            "Epoch 24/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2952 - sparse_categorical_accuracy: 0.9075 - val_loss: 0.2743 - val_sparse_categorical_accuracy: 0.9124\n",
            "Epoch 25/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2903 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.2950 - val_sparse_categorical_accuracy: 0.9080\n",
            "Epoch 26/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2882 - sparse_categorical_accuracy: 0.9093 - val_loss: 0.2815 - val_sparse_categorical_accuracy: 0.9114\n",
            "Epoch 27/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2861 - sparse_categorical_accuracy: 0.9103 - val_loss: 0.2680 - val_sparse_categorical_accuracy: 0.9147\n",
            "Epoch 28/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2826 - sparse_categorical_accuracy: 0.9114 - val_loss: 0.2746 - val_sparse_categorical_accuracy: 0.9137\n",
            "Epoch 29/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2807 - sparse_categorical_accuracy: 0.9124 - val_loss: 0.2686 - val_sparse_categorical_accuracy: 0.9183\n",
            "Epoch 30/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2782 - sparse_categorical_accuracy: 0.9126 - val_loss: 0.2698 - val_sparse_categorical_accuracy: 0.9191\n",
            "Epoch 31/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2758 - sparse_categorical_accuracy: 0.9134 - val_loss: 0.2624 - val_sparse_categorical_accuracy: 0.9175\n",
            "Epoch 32/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2734 - sparse_categorical_accuracy: 0.9146 - val_loss: 0.2577 - val_sparse_categorical_accuracy: 0.9207\n",
            "Epoch 33/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2719 - sparse_categorical_accuracy: 0.9147 - val_loss: 0.2577 - val_sparse_categorical_accuracy: 0.9191\n",
            "Epoch 34/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2689 - sparse_categorical_accuracy: 0.9159 - val_loss: 0.2502 - val_sparse_categorical_accuracy: 0.9214\n",
            "Epoch 35/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2673 - sparse_categorical_accuracy: 0.9158 - val_loss: 0.2497 - val_sparse_categorical_accuracy: 0.9215\n",
            "Epoch 36/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2651 - sparse_categorical_accuracy: 0.9168 - val_loss: 0.2551 - val_sparse_categorical_accuracy: 0.9208\n",
            "Epoch 37/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2636 - sparse_categorical_accuracy: 0.9171 - val_loss: 0.2450 - val_sparse_categorical_accuracy: 0.9236\n",
            "Epoch 38/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2620 - sparse_categorical_accuracy: 0.9186 - val_loss: 0.2434 - val_sparse_categorical_accuracy: 0.9243\n",
            "Epoch 39/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2600 - sparse_categorical_accuracy: 0.9186 - val_loss: 0.2635 - val_sparse_categorical_accuracy: 0.9177\n",
            "Epoch 40/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2579 - sparse_categorical_accuracy: 0.9191 - val_loss: 0.2460 - val_sparse_categorical_accuracy: 0.9242\n",
            "Epoch 41/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2576 - sparse_categorical_accuracy: 0.9189 - val_loss: 0.2404 - val_sparse_categorical_accuracy: 0.9249\n",
            "Epoch 42/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2537 - sparse_categorical_accuracy: 0.9204 - val_loss: 0.2370 - val_sparse_categorical_accuracy: 0.9262\n",
            "Epoch 43/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2534 - sparse_categorical_accuracy: 0.9210 - val_loss: 0.2363 - val_sparse_categorical_accuracy: 0.9255\n",
            "Epoch 44/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2518 - sparse_categorical_accuracy: 0.9209 - val_loss: 0.2330 - val_sparse_categorical_accuracy: 0.9262\n",
            "Epoch 45/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2507 - sparse_categorical_accuracy: 0.9214 - val_loss: 0.2442 - val_sparse_categorical_accuracy: 0.9241\n",
            "Epoch 46/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2494 - sparse_categorical_accuracy: 0.9220 - val_loss: 0.2346 - val_sparse_categorical_accuracy: 0.9267\n",
            "Epoch 47/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2484 - sparse_categorical_accuracy: 0.9225 - val_loss: 0.2325 - val_sparse_categorical_accuracy: 0.9267\n",
            "Epoch 48/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2456 - sparse_categorical_accuracy: 0.9236 - val_loss: 0.2447 - val_sparse_categorical_accuracy: 0.9227\n",
            "Epoch 49/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2440 - sparse_categorical_accuracy: 0.9234 - val_loss: 0.2321 - val_sparse_categorical_accuracy: 0.9278\n",
            "Epoch 50/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2437 - sparse_categorical_accuracy: 0.9238 - val_loss: 0.2243 - val_sparse_categorical_accuracy: 0.9302\n",
            "Epoch 51/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2422 - sparse_categorical_accuracy: 0.9248 - val_loss: 0.2471 - val_sparse_categorical_accuracy: 0.9232\n",
            "Epoch 52/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2418 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.2212 - val_sparse_categorical_accuracy: 0.9322\n",
            "Epoch 53/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2399 - sparse_categorical_accuracy: 0.9260 - val_loss: 0.2232 - val_sparse_categorical_accuracy: 0.9285\n",
            "Epoch 54/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2386 - sparse_categorical_accuracy: 0.9258 - val_loss: 0.2204 - val_sparse_categorical_accuracy: 0.9324\n",
            "Epoch 55/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2373 - sparse_categorical_accuracy: 0.9261 - val_loss: 0.2210 - val_sparse_categorical_accuracy: 0.9315\n",
            "Epoch 56/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2374 - sparse_categorical_accuracy: 0.9262 - val_loss: 0.2231 - val_sparse_categorical_accuracy: 0.9312\n",
            "Epoch 57/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2353 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.2180 - val_sparse_categorical_accuracy: 0.9335\n",
            "Epoch 58/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2346 - sparse_categorical_accuracy: 0.9269 - val_loss: 0.2142 - val_sparse_categorical_accuracy: 0.9347\n",
            "Epoch 59/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2328 - sparse_categorical_accuracy: 0.9281 - val_loss: 0.2213 - val_sparse_categorical_accuracy: 0.9348\n",
            "Epoch 60/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2313 - sparse_categorical_accuracy: 0.9285 - val_loss: 0.2121 - val_sparse_categorical_accuracy: 0.9344\n",
            "Epoch 61/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2304 - sparse_categorical_accuracy: 0.9285 - val_loss: 0.2160 - val_sparse_categorical_accuracy: 0.9334\n",
            "Epoch 62/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2300 - sparse_categorical_accuracy: 0.9281 - val_loss: 0.2088 - val_sparse_categorical_accuracy: 0.9355\n",
            "Epoch 63/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2276 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.2083 - val_sparse_categorical_accuracy: 0.9363\n",
            "Epoch 64/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2266 - sparse_categorical_accuracy: 0.9301 - val_loss: 0.2238 - val_sparse_categorical_accuracy: 0.9303\n",
            "Epoch 65/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2266 - sparse_categorical_accuracy: 0.9297 - val_loss: 0.2235 - val_sparse_categorical_accuracy: 0.9310\n",
            "Epoch 66/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2253 - sparse_categorical_accuracy: 0.9302 - val_loss: 0.2106 - val_sparse_categorical_accuracy: 0.9342\n",
            "Epoch 67/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2226 - sparse_categorical_accuracy: 0.9310 - val_loss: 0.2267 - val_sparse_categorical_accuracy: 0.9283\n",
            "Epoch 68/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2228 - sparse_categorical_accuracy: 0.9309 - val_loss: 0.2073 - val_sparse_categorical_accuracy: 0.9353\n",
            "Epoch 69/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2208 - sparse_categorical_accuracy: 0.9310 - val_loss: 0.2079 - val_sparse_categorical_accuracy: 0.9355\n",
            "Epoch 70/100\n",
            "234649/234649 [==============================] - 12s 53us/sample - loss: 0.2205 - sparse_categorical_accuracy: 0.9314 - val_loss: 0.2033 - val_sparse_categorical_accuracy: 0.9365\n",
            "Epoch 71/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2184 - sparse_categorical_accuracy: 0.9317 - val_loss: 0.2022 - val_sparse_categorical_accuracy: 0.9367\n",
            "Epoch 72/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2175 - sparse_categorical_accuracy: 0.9323 - val_loss: 0.2047 - val_sparse_categorical_accuracy: 0.9369\n",
            "Epoch 73/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2163 - sparse_categorical_accuracy: 0.9329 - val_loss: 0.1988 - val_sparse_categorical_accuracy: 0.9383\n",
            "Epoch 74/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2150 - sparse_categorical_accuracy: 0.9327 - val_loss: 0.1997 - val_sparse_categorical_accuracy: 0.9368\n",
            "Epoch 75/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2145 - sparse_categorical_accuracy: 0.9332 - val_loss: 0.1980 - val_sparse_categorical_accuracy: 0.9400\n",
            "Epoch 76/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2120 - sparse_categorical_accuracy: 0.9341 - val_loss: 0.1936 - val_sparse_categorical_accuracy: 0.9399\n",
            "Epoch 77/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2109 - sparse_categorical_accuracy: 0.9344 - val_loss: 0.1930 - val_sparse_categorical_accuracy: 0.9390\n",
            "Epoch 78/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2093 - sparse_categorical_accuracy: 0.9352 - val_loss: 0.1929 - val_sparse_categorical_accuracy: 0.9414\n",
            "Epoch 79/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2090 - sparse_categorical_accuracy: 0.9354 - val_loss: 0.1885 - val_sparse_categorical_accuracy: 0.9427\n",
            "Epoch 80/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2079 - sparse_categorical_accuracy: 0.9354 - val_loss: 0.1899 - val_sparse_categorical_accuracy: 0.9422\n",
            "Epoch 81/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2057 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.2083 - val_sparse_categorical_accuracy: 0.9334\n",
            "Epoch 82/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2054 - sparse_categorical_accuracy: 0.9365 - val_loss: 0.1895 - val_sparse_categorical_accuracy: 0.9411\n",
            "Epoch 83/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2031 - sparse_categorical_accuracy: 0.9377 - val_loss: 0.1874 - val_sparse_categorical_accuracy: 0.9413\n",
            "Epoch 84/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2028 - sparse_categorical_accuracy: 0.9372 - val_loss: 0.2000 - val_sparse_categorical_accuracy: 0.9374\n",
            "Epoch 85/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2020 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1857 - val_sparse_categorical_accuracy: 0.9438\n",
            "Epoch 86/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1998 - sparse_categorical_accuracy: 0.9386 - val_loss: 0.1832 - val_sparse_categorical_accuracy: 0.9435\n",
            "Epoch 87/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.2000 - sparse_categorical_accuracy: 0.9384 - val_loss: 0.1890 - val_sparse_categorical_accuracy: 0.9421\n",
            "Epoch 88/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1990 - sparse_categorical_accuracy: 0.9387 - val_loss: 0.1885 - val_sparse_categorical_accuracy: 0.9406\n",
            "Epoch 89/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1976 - sparse_categorical_accuracy: 0.9391 - val_loss: 0.1885 - val_sparse_categorical_accuracy: 0.9411\n",
            "Epoch 90/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1957 - sparse_categorical_accuracy: 0.9399 - val_loss: 0.1762 - val_sparse_categorical_accuracy: 0.9464\n",
            "Epoch 91/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1969 - sparse_categorical_accuracy: 0.9395 - val_loss: 0.1764 - val_sparse_categorical_accuracy: 0.9461\n",
            "Epoch 92/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1945 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1823 - val_sparse_categorical_accuracy: 0.9443\n",
            "Epoch 93/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1951 - sparse_categorical_accuracy: 0.9399 - val_loss: 0.1795 - val_sparse_categorical_accuracy: 0.9441\n",
            "Epoch 94/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1934 - sparse_categorical_accuracy: 0.9404 - val_loss: 0.1910 - val_sparse_categorical_accuracy: 0.9393\n",
            "Epoch 95/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1937 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1731 - val_sparse_categorical_accuracy: 0.9465\n",
            "Epoch 96/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1921 - sparse_categorical_accuracy: 0.9411 - val_loss: 0.1764 - val_sparse_categorical_accuracy: 0.9460\n",
            "Epoch 97/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1916 - sparse_categorical_accuracy: 0.9408 - val_loss: 0.1886 - val_sparse_categorical_accuracy: 0.9404\n",
            "Epoch 98/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1907 - sparse_categorical_accuracy: 0.9414 - val_loss: 0.1765 - val_sparse_categorical_accuracy: 0.9455\n",
            "Epoch 99/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1916 - sparse_categorical_accuracy: 0.9411 - val_loss: 0.1752 - val_sparse_categorical_accuracy: 0.9453\n",
            "Epoch 100/100\n",
            "234649/234649 [==============================] - 12s 52us/sample - loss: 0.1886 - sparse_categorical_accuracy: 0.9422 - val_loss: 0.1699 - val_sparse_categorical_accuracy: 0.9476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RUSN-Yc4oHz",
        "colab_type": "code",
        "outputId": "81593cfb-a729-4131-f473-b8f262bd7d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        }
      },
      "source": [
        "graficarMatrizConfusion(y_true=y_test, y_pred=modelo1.predict_classes(x_test_1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-23-35f703ade7e7>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAHuCAYAAAC/PiQSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDtsAO4oE9I9",
        "colab_type": "text"
      },
      "source": [
        "# Modelo CNN 2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv1RWDQcYdv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crearModelo2D(pTasa, pAlpha, pNumFiltros, pTamFiltros, pTamPooling, pNumNeuronas, pOptimizer, T_entrada_1, T_entrada_2):\n",
        "\n",
        "  modelo = Sequential()\n",
        "\n",
        "  modelo.add(Input(shape = (1,T_entrada_1,T_entrada_2)))\n",
        "\n",
        "  modelo.add(Conv2D(pNumFiltros[0], (int(pTamFiltros[0]),int(pTamFiltros[0])), padding='same', activation = 'relu'))\n",
        "  modelo.add(Conv2D(pNumFiltros[1], (int(pTamFiltros[1]),int(pTamFiltros[1])), padding='same', activation = 'relu'))\n",
        "  modelo.add(Conv2D(pNumFiltros[2], (int(pTamFiltros[2]),int(pTamFiltros[2])), padding='same', activation = 'relu'))\n",
        "  modelo.add(Conv2D(pNumFiltros[3], (int(pTamFiltros[3]),int(pTamFiltros[3])), padding='same', activation = 'relu'))\n",
        "  #modelo.add(Conv2D(pNumFiltros[4], (int(pTamFiltros[4]),int(pTamFiltros[4])), padding='same', activation = 'relu'))\n",
        "  #modelo.add(Conv2D(pNumFiltros[5], (int(pTamFiltros[5]),int(pTamFiltros[5])), padding='same', activation = 'relu'))\n",
        "\n",
        "  modelo.add(MaxPooling2D((int(pTamFiltros[1]),int(pTamFiltros[1])), padding='same'))\n",
        "\n",
        "\n",
        "\n",
        "  modelo.add(Dropout(0.5))\n",
        "  modelo.add(Flatten())\n",
        "\n",
        "  modelo.add(Dense(pNumNeuronas[0], activation='relu'))\n",
        "  modelo.add(Dense(pNumNeuronas[1], activation='relu'))\n",
        "  modelo.add(Dense(pNumNeuronas[2], activation='relu'))\n",
        "  #modelo.add(Dense(pNumNeuronas[3], activation='relu'))\n",
        "\n",
        "  modelo.add(Dense(4, activation='softmax'))\n",
        "\n",
        "\n",
        "  sgd = optimizers.SGD(lr = pTasa)#, momentum=0.9)\n",
        "  adam = optimizers.Adam(learning_rate = pTasa)\n",
        "  if pOptimizer == \"adam\":\n",
        "    opt=adam\n",
        "  elif pOptimizer ==\"sgd\":\n",
        "    opt=sgd\n",
        "  elif pOptimizer ==\"rmsprop\":\n",
        "    opt = \"rmsprop\"\n",
        "  \n",
        "  modelo.compile(loss='sparse_categorical_crossentropy', optimizer = opt, metrics = ['sparse_categorical_accuracy'])\n",
        "  modelo.summary()\n",
        "  \n",
        "  return modelo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WMqRdTt2U2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Esta celda construye los modelos, a partir de los parametros especificados por cada una de las siguientes variables.\n",
        "#Es el numero de filtros que cada capa convolucional utiliza.\n",
        "numFiltros = np.array([10, 10, 10, 10, 10, 512])\n",
        "\n",
        "#Es el tamaño de los filtros utilizados en cada capa convolucional.\n",
        "tamFiltros = np.array([2, 4, 4, 3, 3, 5])\n",
        "\n",
        "#Es el tamaño de cada capa de Pooling.\n",
        "tamPooling = np.array([4, 2, 3, 3, 3, 3])\n",
        "\n",
        "#Es el numero de neuronas en cada capa de la red neuronal que sigue despues de la parte convolucional.\n",
        "numNeuronas = np.array([10, 10, 10, 16])\n",
        "\n",
        "#Es el tipo de optimizador a utilizar.\n",
        "#Se pueden especificar: \"sgd\", \"adam\" o \"rmsprop\"\n",
        "optimizer=\"rmsprop\"\n",
        "\n",
        "#Es la tasa de aprendizaje del optimizador.\n",
        "tasa = 0.1\n",
        "\n",
        "#Es el parametro de regularizacion a utilizar.\n",
        "alpha = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LJXcB-i2fQb",
        "colab_type": "code",
        "outputId": "d5b42965-0a40-4971-b738-83d20e54aff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Numero_Datos, uno, alto_2, ancho_2=x_train_2.shape\n",
        "\n",
        "modelo2 = crearModelo2D(tasa, alpha, numFiltros, tamFiltros, tamPooling, numNeuronas, optimizer, T_entrada_1 = alto_2 , T_entrada_2 = ancho_2 )\n",
        "\n",
        "#Esta linea muestra un diagrama de la red neuronal.\n",
        "SVG(model_to_dot(modelo2, show_shapes = True, expand_nested = True, dpi = 50).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 1, 128, 16)        144       \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 1, 128, 32)        8224      \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 1, 128, 64)        32832     \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 1, 128, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 32, 128)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1, 32, 128)        0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 10)                40970     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 4)                 44        \n",
            "=================================================================\n",
            "Total params: 156,290\n",
            "Trainable params: 156,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"672pt\" viewBox=\"0.00 0.00 394.00 968.00\" width=\"274pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.6944 .6944) rotate(0) translate(4 964)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-964 390,-964 390,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139800649671064 -->\n<g class=\"node\" id=\"node1\">\n<title>139800649671064</title>\n<polygon fill=\"none\" points=\"47,-913.5 47,-959.5 339,-959.5 339,-913.5 47,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-932.8\">input_7: InputLayer</text>\n<polyline fill=\"none\" points=\"180,-913.5 180,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"180,-936.5 238,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"238,-913.5 238,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-944.3\">[(?, 1, 128, 2)]</text>\n<polyline fill=\"none\" points=\"238,-936.5 339,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-921.3\">[(?, 1, 128, 2)]</text>\n</g>\n<!-- 139800649671680 -->\n<g class=\"node\" id=\"node2\">\n<title>139800649671680</title>\n<polygon fill=\"none\" points=\"44.5,-830.5 44.5,-876.5 341.5,-876.5 341.5,-830.5 44.5,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-849.8\">conv2d_16: Conv2D</text>\n<polyline fill=\"none\" points=\"184.5,-830.5 184.5,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"184.5,-853.5 242.5,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"242.5,-830.5 242.5,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292\" y=\"-861.3\">(?, 1, 128, 2)</text>\n<polyline fill=\"none\" points=\"242.5,-853.5 341.5,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292\" y=\"-838.3\">(?, 1, 128, 16)</text>\n</g>\n<!-- 139800649671064&#45;&gt;139800649671680 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139800649671064-&gt;139800649671680</title>\n<path d=\"M193,-913.3799C193,-905.1745 193,-895.7679 193,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.5001,-886.784 193,-876.784 189.5001,-886.784 196.5001,-886.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139800649672856 -->\n<g class=\"node\" id=\"node3\">\n<title>139800649672856</title>\n<polygon fill=\"none\" points=\"44.5,-747.5 44.5,-793.5 341.5,-793.5 341.5,-747.5 44.5,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-766.8\">conv2d_17: Conv2D</text>\n<polyline fill=\"none\" points=\"184.5,-747.5 184.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"184.5,-770.5 242.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"242.5,-747.5 242.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292\" y=\"-778.3\">(?, 1, 128, 16)</text>\n<polyline fill=\"none\" points=\"242.5,-770.5 341.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292\" y=\"-755.3\">(?, 1, 128, 32)</text>\n</g>\n<!-- 139800649671680&#45;&gt;139800649672856 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139800649671680-&gt;139800649672856</title>\n<path d=\"M193,-830.3799C193,-822.1745 193,-812.7679 193,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.5001,-803.784 193,-793.784 189.5001,-803.784 196.5001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139800649477536 -->\n<g class=\"node\" id=\"node4\">\n<title>139800649477536</title>\n<polygon fill=\"none\" points=\"44.5,-664.5 44.5,-710.5 341.5,-710.5 341.5,-664.5 44.5,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-683.8\">conv2d_18: Conv2D</text>\n<polyline fill=\"none\" points=\"184.5,-664.5 184.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"184.5,-687.5 242.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"242.5,-664.5 242.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292\" y=\"-695.3\">(?, 1, 128, 32)</text>\n<polyline fill=\"none\" points=\"242.5,-687.5 341.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292\" y=\"-672.3\">(?, 1, 128, 64)</text>\n</g>\n<!-- 139800649672856&#45;&gt;139800649477536 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139800649672856-&gt;139800649477536</title>\n<path d=\"M193,-747.3799C193,-739.1745 193,-729.7679 193,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.5001,-720.784 193,-710.784 189.5001,-720.784 196.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139799020208704 -->\n<g class=\"node\" id=\"node5\">\n<title>139799020208704</title>\n<polygon fill=\"none\" points=\"40.5,-581.5 40.5,-627.5 345.5,-627.5 345.5,-581.5 40.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-600.8\">conv2d_19: Conv2D</text>\n<polyline fill=\"none\" points=\"180.5,-581.5 180.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"180.5,-604.5 238.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"238.5,-581.5 238.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292\" y=\"-612.3\">(?, 1, 128, 64)</text>\n<polyline fill=\"none\" points=\"238.5,-604.5 345.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292\" y=\"-589.3\">(?, 1, 128, 128)</text>\n</g>\n<!-- 139800649477536&#45;&gt;139799020208704 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139800649477536-&gt;139799020208704</title>\n<path d=\"M193,-664.3799C193,-656.1745 193,-646.7679 193,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.5001,-637.784 193,-627.784 189.5001,-637.784 196.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139800649368296 -->\n<g class=\"node\" id=\"node6\">\n<title>139800649368296</title>\n<polygon fill=\"none\" points=\"0,-498.5 0,-544.5 386,-544.5 386,-498.5 0,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-517.8\">max_pooling2d_4: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"221,-498.5 221,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"221,-521.5 279,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"279,-498.5 279,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332.5\" y=\"-529.3\">(?, 1, 128, 128)</text>\n<polyline fill=\"none\" points=\"279,-521.5 386,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332.5\" y=\"-506.3\">(?, 1, 32, 128)</text>\n</g>\n<!-- 139799020208704&#45;&gt;139800649368296 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139799020208704-&gt;139800649368296</title>\n<path d=\"M193,-581.3799C193,-573.1745 193,-563.7679 193,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.5001,-554.784 193,-544.784 189.5001,-554.784 196.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139800649672912 -->\n<g class=\"node\" id=\"node7\">\n<title>139800649672912</title>\n<polygon fill=\"none\" points=\"47.5,-415.5 47.5,-461.5 338.5,-461.5 338.5,-415.5 47.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-434.8\">dropout_6: Dropout</text>\n<polyline fill=\"none\" points=\"181.5,-415.5 181.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"181.5,-438.5 239.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"239.5,-415.5 239.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289\" y=\"-446.3\">(?, 1, 32, 128)</text>\n<polyline fill=\"none\" points=\"239.5,-438.5 338.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289\" y=\"-423.3\">(?, 1, 32, 128)</text>\n</g>\n<!-- 139800649368296&#45;&gt;139800649672912 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139800649368296-&gt;139800649672912</title>\n<path d=\"M193,-498.3799C193,-490.1745 193,-480.7679 193,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.5001,-471.784 193,-461.784 189.5001,-471.784 196.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139800649249680 -->\n<g class=\"node\" id=\"node8\">\n<title>139800649249680</title>\n<polygon fill=\"none\" points=\"58,-332.5 58,-378.5 328,-378.5 328,-332.5 58,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-351.8\">flatten_6: Flatten</text>\n<polyline fill=\"none\" points=\"171,-332.5 171,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"171,-355.5 229,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"229,-332.5 229,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-363.3\">(?, 1, 32, 128)</text>\n<polyline fill=\"none\" points=\"229,-355.5 328,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-340.3\">(?, 4096)</text>\n</g>\n<!-- 139800649672912&#45;&gt;139800649249680 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139800649672912-&gt;139800649249680</title>\n<path d=\"M193,-415.3799C193,-407.1745 193,-397.7679 193,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.5001,-388.784 193,-378.784 189.5001,-388.784 196.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139800649272400 -->\n<g class=\"node\" id=\"node9\">\n<title>139800649272400</title>\n<polygon fill=\"none\" points=\"72.5,-249.5 72.5,-295.5 313.5,-295.5 313.5,-249.5 72.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"129.5\" y=\"-268.8\">dense_22: Dense</text>\n<polyline fill=\"none\" points=\"186.5,-249.5 186.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"186.5,-272.5 244.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"244.5,-249.5 244.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-280.3\">(?, 4096)</text>\n<polyline fill=\"none\" points=\"244.5,-272.5 313.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-257.3\">(?, 10)</text>\n</g>\n<!-- 139800649249680&#45;&gt;139800649272400 -->\n<g class=\"edge\" id=\"edge8\">\n<title>139800649249680-&gt;139800649272400</title>\n<path d=\"M193,-332.3799C193,-324.1745 193,-314.7679 193,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.5001,-305.784 193,-295.784 189.5001,-305.784 196.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139799019788384 -->\n<g class=\"node\" id=\"node10\">\n<title>139799019788384</title>\n<polygon fill=\"none\" points=\"80,-166.5 80,-212.5 306,-212.5 306,-166.5 80,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-185.8\">dense_23: Dense</text>\n<polyline fill=\"none\" points=\"194,-166.5 194,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"194,-189.5 252,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"252,-166.5 252,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-197.3\">(?, 10)</text>\n<polyline fill=\"none\" points=\"252,-189.5 306,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-174.3\">(?, 10)</text>\n</g>\n<!-- 139800649272400&#45;&gt;139799019788384 -->\n<g class=\"edge\" id=\"edge9\">\n<title>139800649272400-&gt;139799019788384</title>\n<path d=\"M193,-249.3799C193,-241.1745 193,-231.7679 193,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.5001,-222.784 193,-212.784 189.5001,-222.784 196.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139799019758144 -->\n<g class=\"node\" id=\"node11\">\n<title>139799019758144</title>\n<polygon fill=\"none\" points=\"80,-83.5 80,-129.5 306,-129.5 306,-83.5 80,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-102.8\">dense_24: Dense</text>\n<polyline fill=\"none\" points=\"194,-83.5 194,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"194,-106.5 252,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"252,-83.5 252,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-114.3\">(?, 10)</text>\n<polyline fill=\"none\" points=\"252,-106.5 306,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-91.3\">(?, 10)</text>\n</g>\n<!-- 139799019788384&#45;&gt;139799019758144 -->\n<g class=\"edge\" id=\"edge10\">\n<title>139799019788384-&gt;139799019758144</title>\n<path d=\"M193,-166.3799C193,-158.1745 193,-148.7679 193,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.5001,-139.784 193,-129.784 189.5001,-139.784 196.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139799019759712 -->\n<g class=\"node\" id=\"node12\">\n<title>139799019759712</title>\n<polygon fill=\"none\" points=\"80,-.5 80,-46.5 306,-46.5 306,-.5 80,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-19.8\">dense_25: Dense</text>\n<polyline fill=\"none\" points=\"194,-.5 194,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"194,-23.5 252,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"252,-.5 252,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-31.3\">(?, 10)</text>\n<polyline fill=\"none\" points=\"252,-23.5 306,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-8.3\">(?, 4)</text>\n</g>\n<!-- 139799019758144&#45;&gt;139799019759712 -->\n<g class=\"edge\" id=\"edge11\">\n<title>139799019758144-&gt;139799019759712</title>\n<path d=\"M193,-83.3799C193,-75.1745 193,-65.7679 193,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.5001,-56.784 193,-46.784 189.5001,-56.784 196.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgTxJfoc2ava",
        "colab_type": "code",
        "outputId": "4bae1bac-c5ef-4fbb-a6f6-8331839b7a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epocas = 100\n",
        "batchSize = 5000\n",
        "\n",
        "#modelo1.compile(loss='sparse_categorical_crossentropy', optimizer = \"rmsprop\", metrics = ['sparse_categorical_accuracy'])\n",
        "\n",
        "for i in range(0,1):\n",
        "  #hist = modelo1.fit(x, y, verbose = 1, validation_data=(x, y), epochs = epocas, batch_size = batchSize)#, class_weight = pesosClases)\n",
        "  hist = modelo2.fit(x_train_2, y_train, validation_data=(x_test_2, y_test), epochs = epocas, batch_size = batchSize, class_weight = pesosClases)\n",
        " \n",
        "                        \n",
        "\n",
        "  #SVG(model_to_dot(modelo1, show_shapes = True, expand_nested = True, dpi = 60).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1019232 samples, validate on 254808 samples\n",
            "Epoch 1/100\n",
            "1019232/1019232 [==============================] - 31s 30us/sample - loss: 0.5502 - sparse_categorical_accuracy: 0.8324 - val_loss: 0.3916 - val_sparse_categorical_accuracy: 0.8936\n",
            "Epoch 2/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.3560 - sparse_categorical_accuracy: 0.8995 - val_loss: 0.3160 - val_sparse_categorical_accuracy: 0.9143\n",
            "Epoch 3/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.2779 - sparse_categorical_accuracy: 0.9234 - val_loss: 0.2572 - val_sparse_categorical_accuracy: 0.9281\n",
            "Epoch 4/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.2368 - sparse_categorical_accuracy: 0.9362 - val_loss: 0.1926 - val_sparse_categorical_accuracy: 0.9504\n",
            "Epoch 5/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.2123 - sparse_categorical_accuracy: 0.9436 - val_loss: 0.1796 - val_sparse_categorical_accuracy: 0.9518\n",
            "Epoch 6/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1989 - sparse_categorical_accuracy: 0.9468 - val_loss: 0.2401 - val_sparse_categorical_accuracy: 0.9395\n",
            "Epoch 7/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1854 - sparse_categorical_accuracy: 0.9512 - val_loss: 0.1846 - val_sparse_categorical_accuracy: 0.9527\n",
            "Epoch 8/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1776 - sparse_categorical_accuracy: 0.9536 - val_loss: 0.1474 - val_sparse_categorical_accuracy: 0.9628\n",
            "Epoch 9/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1701 - sparse_categorical_accuracy: 0.9554 - val_loss: 0.1898 - val_sparse_categorical_accuracy: 0.9507\n",
            "Epoch 10/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1622 - sparse_categorical_accuracy: 0.9576 - val_loss: 0.1770 - val_sparse_categorical_accuracy: 0.9556\n",
            "Epoch 11/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1562 - sparse_categorical_accuracy: 0.9595 - val_loss: 0.1414 - val_sparse_categorical_accuracy: 0.9631\n",
            "Epoch 12/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1518 - sparse_categorical_accuracy: 0.9604 - val_loss: 0.1335 - val_sparse_categorical_accuracy: 0.9659\n",
            "Epoch 13/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1469 - sparse_categorical_accuracy: 0.9620 - val_loss: 0.1364 - val_sparse_categorical_accuracy: 0.9646\n",
            "Epoch 14/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1432 - sparse_categorical_accuracy: 0.9629 - val_loss: 0.1570 - val_sparse_categorical_accuracy: 0.9592\n",
            "Epoch 15/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1396 - sparse_categorical_accuracy: 0.9639 - val_loss: 0.1151 - val_sparse_categorical_accuracy: 0.9711\n",
            "Epoch 16/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1382 - sparse_categorical_accuracy: 0.9643 - val_loss: 0.1142 - val_sparse_categorical_accuracy: 0.9713\n",
            "Epoch 17/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1341 - sparse_categorical_accuracy: 0.9653 - val_loss: 0.1126 - val_sparse_categorical_accuracy: 0.9715\n",
            "Epoch 18/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1325 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.1429 - val_sparse_categorical_accuracy: 0.9632\n",
            "Epoch 19/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1305 - sparse_categorical_accuracy: 0.9662 - val_loss: 0.1096 - val_sparse_categorical_accuracy: 0.9724\n",
            "Epoch 20/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1284 - sparse_categorical_accuracy: 0.9666 - val_loss: 0.1338 - val_sparse_categorical_accuracy: 0.9655\n",
            "Epoch 21/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1277 - sparse_categorical_accuracy: 0.9668 - val_loss: 0.1080 - val_sparse_categorical_accuracy: 0.9725\n",
            "Epoch 22/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1247 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.1146 - val_sparse_categorical_accuracy: 0.9702\n",
            "Epoch 23/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1247 - sparse_categorical_accuracy: 0.9678 - val_loss: 0.1056 - val_sparse_categorical_accuracy: 0.9732\n",
            "Epoch 24/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1222 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1230 - val_sparse_categorical_accuracy: 0.9685\n",
            "Epoch 25/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1210 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.1047 - val_sparse_categorical_accuracy: 0.9730\n",
            "Epoch 26/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1197 - sparse_categorical_accuracy: 0.9689 - val_loss: 0.1277 - val_sparse_categorical_accuracy: 0.9675\n",
            "Epoch 27/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1190 - sparse_categorical_accuracy: 0.9692 - val_loss: 0.1136 - val_sparse_categorical_accuracy: 0.9713\n",
            "Epoch 28/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1175 - sparse_categorical_accuracy: 0.9695 - val_loss: 0.1304 - val_sparse_categorical_accuracy: 0.9663\n",
            "Epoch 29/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1168 - sparse_categorical_accuracy: 0.9696 - val_loss: 0.1051 - val_sparse_categorical_accuracy: 0.9736\n",
            "Epoch 30/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1157 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.1074 - val_sparse_categorical_accuracy: 0.9727\n",
            "Epoch 31/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1141 - sparse_categorical_accuracy: 0.9702 - val_loss: 0.1057 - val_sparse_categorical_accuracy: 0.9727\n",
            "Epoch 32/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1135 - sparse_categorical_accuracy: 0.9704 - val_loss: 0.1108 - val_sparse_categorical_accuracy: 0.9720\n",
            "Epoch 33/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1126 - sparse_categorical_accuracy: 0.9706 - val_loss: 0.0999 - val_sparse_categorical_accuracy: 0.9744\n",
            "Epoch 34/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1121 - sparse_categorical_accuracy: 0.9709 - val_loss: 0.0954 - val_sparse_categorical_accuracy: 0.9757\n",
            "Epoch 35/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1110 - sparse_categorical_accuracy: 0.9710 - val_loss: 0.1081 - val_sparse_categorical_accuracy: 0.9726\n",
            "Epoch 36/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1107 - sparse_categorical_accuracy: 0.9711 - val_loss: 0.1031 - val_sparse_categorical_accuracy: 0.9733\n",
            "Epoch 37/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1094 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.0936 - val_sparse_categorical_accuracy: 0.9758\n",
            "Epoch 38/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1089 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.0944 - val_sparse_categorical_accuracy: 0.9758\n",
            "Epoch 39/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1081 - sparse_categorical_accuracy: 0.9717 - val_loss: 0.1099 - val_sparse_categorical_accuracy: 0.9715\n",
            "Epoch 40/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1076 - sparse_categorical_accuracy: 0.9720 - val_loss: 0.0962 - val_sparse_categorical_accuracy: 0.9750\n",
            "Epoch 41/100\n",
            "1019232/1019232 [==============================] - 29s 29us/sample - loss: 0.1069 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0944 - val_sparse_categorical_accuracy: 0.9757\n",
            "Epoch 42/100\n",
            "1019232/1019232 [==============================] - 32s 32us/sample - loss: 0.1062 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.1050 - val_sparse_categorical_accuracy: 0.9732\n",
            "Epoch 43/100\n",
            " 840000/1019232 [=======================>......] - ETA: 4s - loss: 0.1064 - sparse_categorical_accuracy: 0.9721"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-6499a5aa6f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#hist = modelo1.fit(x, y, verbose = 1, validation_data=(x, y), epochs = epocas, batch_size = batchSize)#, class_weight = pesosClases)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelo2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepocas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpesosClases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdyWApH34tHk",
        "colab_type": "code",
        "outputId": "0640ffc9-33f0-4005-c9b0-0d618c8135bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        }
      },
      "source": [
        "graficarMatrizConfusion(y_true=y_test, y_pred=modelo2.predict_classes(x_test_2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAHuCAYAAAC/PiQSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngHBiDQDhxBoAwok1AIT7ARcUQ9ewJntGAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQWpeq3ShE7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graficarMatrizConfusion(y_true=y_test, y_pred=modelo2.predict_classes(x_test_2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8gAttxY9S12",
        "colab_type": "text"
      },
      "source": [
        "# Modelo CNN 1D y 2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7VWpqoH9Sjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crearModelo_1D_y_2D(pTasa, pAlpha, pNumFiltros, pTamFiltros, pTamPooling, pNumNeuronas, pOptimizer, T_entrada_1, T_entrada_2, T_entrada_3):\n",
        "  # CONV 1D\n",
        "  capaEntrada_1 = Input(shape = (T_entrada_3,1))\n",
        "\n",
        "  capa1_1 = Conv1D(pNumFiltros[0], int(pTamFiltros[0]), padding='same', activation = 'relu')(capaEntrada_1)\n",
        "  pooling1_1 = MaxPooling1D(int(pTamPooling[0]), padding='same')(capa1_1)\n",
        "\n",
        "  capa2_1 = Conv1D(pNumFiltros[1], int(pTamFiltros[1]), padding='same', activation = 'relu')(pooling1_1)\n",
        "  pooling2_1 = MaxPooling1D(int(pTamPooling[1]), padding='same')(capa2_1)\n",
        "  \n",
        "  flatten_1 = Flatten()(pooling2_1)\n",
        "\n",
        "  # CONV 2D\n",
        "  capaEntrada_2 = Input(shape = (1,T_entrada_1,T_entrada_2))\n",
        "\n",
        "  capa1_2 = Conv2D(pNumFiltros[0], int(pTamFiltros[0]), padding='same', activation = 'relu')(capaEntrada_2)\n",
        "  pooling1_2 = MaxPooling2D(int(pTamPooling[0]), padding='same')(capa1_2)\n",
        "\n",
        "  capa2_2 = Conv2D(pNumFiltros[1], int(pTamFiltros[1]), padding='same', activation = 'relu')(pooling1_2)\n",
        "  pooling2_2 = MaxPooling2D(int(pTamPooling[1]), padding='same')(capa2_2)\n",
        "  \n",
        "  flatten_2 = Flatten()(pooling2_2)\n",
        "\n",
        "\n",
        "  capas = concatenate([flatten_1, flatten_2])\n",
        "\n",
        "  capas = Dropout(0.5)(capas)\n",
        "  \n",
        "  capas = Dense(pNumNeuronas[0], activation='relu')(capas)\n",
        "  capas = Dense(pNumNeuronas[1], activation='relu')(capas)\n",
        "\n",
        "  capaSalida = Dense(4, activation='softmax')(capas)\n",
        "\n",
        "  #modelo = Sequential()\n",
        "  modelo = Model(inputs = [capaEntrada_1, capaEntrada_2], outputs = capaSalida)\n",
        "\n",
        "  sgd = optimizers.SGD(lr = pTasa)#, momentum=0.9)\n",
        "  adam = optimizers.Adam(learning_rate = pTasa)\n",
        "  if pOptimizer == \"adam\":\n",
        "    opt=adam\n",
        "  elif pOptimizer ==\"sgd\":\n",
        "    opt=sgd\n",
        "  elif pOptimizer ==\"rmsprop\":\n",
        "    opt = \"rmsprop\"\n",
        "  \n",
        "  modelo.compile(loss='sparse_categorical_crossentropy', optimizer = opt, metrics = ['sparse_categorical_accuracy'])\n",
        "  modelo.summary()\n",
        "  \n",
        "  return modelo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmDDpgu-_V7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Esta celda construye los modelos, a partir de los parametros especificados por cada una de las siguientes variables.\n",
        "#Es el numero de filtros que cada capa convolucional utiliza.\n",
        "numFiltros = np.array([5, 10, 10, 10, 10, 10])\n",
        "\n",
        "#Es el tamaño de los filtros utilizados en cada capa convolucional.\n",
        "tamFiltros = np.array([10, 10, 10, 8, 8, 5])\n",
        "\n",
        "#Es el tamaño de cada capa de Pooling.\n",
        "tamPooling = np.array([5, 5, 3, 3, 3, 3])\n",
        "\n",
        "#Es el numero de neuronas en cada capa de la red neuronal que sigue despues de la parte convolucional.\n",
        "numNeuronas = np.array([4, 4, 10])\n",
        "\n",
        "#Es el tipo de optimizador a utilizar.\n",
        "#Se pueden especificar: \"sgd\", \"adam\" o \"rmsprop\"\n",
        "optimizer=\"rmsprop\"\n",
        "\n",
        "#Es la tasa de aprendizaje del optimizador.\n",
        "tasa = 0.1\n",
        "\n",
        "#Es el parametro de regularizacion a utilizar.\n",
        "alpha = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlKCT9-R_cDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Numero_Datos, ancho_1, alto_1, =x_train_1.shape\n",
        "Numero_Datos, uno, alto_2, ancho_2=x_train_2.shape\n",
        "\n",
        "modelo3 = crearModelo_1D_y_2D(tasa, alpha, numFiltros, tamFiltros, tamPooling, numNeuronas, optimizer,T_entrada_1=alto_2, T_entrada_2=ancho_2, T_entrada_3=ancho_1)\n",
        "\n",
        "#Esta linea muestra un diagrama de la red neuronal.\n",
        "SVG(model_to_dot(modelo3, show_shapes = True, expand_nested = True, dpi = 50).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5MslqxyAg29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epocas = 100\n",
        "batchSize = 5000\n",
        "\n",
        "#modelo1.compile(loss='sparse_categorical_crossentropy', optimizer = \"rmsprop\", metrics = ['sparse_categorical_accuracy'])\n",
        "\n",
        "for i in range(0,1):\n",
        "  #hist = modelo1.fit(x, y, verbose = 1, validation_data=(x, y), epochs = epocas, batch_size = batchSize)#, class_weight = pesosClases)\n",
        "  hist = modelo3.fit([x_train_1,x_train_2], y_train, validation_data=([x_test_1,x_test_2], y_test), epochs = epocas, batch_size = batchSize, class_weight = pesosClases)\n",
        " \n",
        "                        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZPM86uRAxgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_prob = modelo3.predict ([x_test_1,x_test_2])\n",
        "y_pred_=y_prob.argmax(axis=-1)\n",
        "graficarMatrizConfusion(y_true=y_test, y_pred=y_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCoBXf9oj9VB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_prob = modelo3.predict ([x_test_1,x_test_2])\n",
        "y_pred_=y_prob.argmax(axis=-1)\n",
        "graficarMatrizConfusion(y_true=y_test, y_pred=y_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VxRH3Mb0TaM",
        "colab_type": "text"
      },
      "source": [
        "# Pruebas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goaQsTYDEQ_S",
        "colab_type": "code",
        "outputId": "319ea8d2-ddb6-47fc-a67f-d3b233d44f5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "frameData, fs = librosa.load(\"drive/My Drive/Proyecto Especial Italiano/MIVIA_DB4_dist/training/sounds/00001_6.wav\", sr=16000, res_type='kaiser_fast') #Audio seleccionado\n",
        "ps = librosa.feature.melspectrogram(y=frameData[0:1000], sr=fs, n_fft = 335, hop_length = int(50) )\n",
        "print(ps.shape)\n",
        "S_dB = librosa.power_to_db(ps, ref=np.max)\n",
        "librosa.display.specshow(S_dB, x_axis='time',\n",
        "                        y_axis='mel', sr=fs,hop_length=int(512/4),\n",
        "                          fmax=8000)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5babe27b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niyAIgqArsVgEQRAEXfn/F9HvKwajCF8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOm0ZL2a-TYe",
        "colab_type": "code",
        "outputId": "134eee98-77fa-4d72-d000-ad0db16caf10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "source": [
        "frameData, fs = librosa.load(\"drive/My Drive/Proyecto Especial Italiano/MIVIA_DB4_dist/training/sounds/00001_6.wav\", sr=16000, res_type='kaiser_fast') #Audio seleccionado\n",
        "ps = librosa.feature.mfcc(y=frameData[0:800], sr=fs, n_mfcc=13, n_fft = 490, hop_length = 10, htk=True )\n",
        "#ps = preprocessing.scale(ps, axis=1)\n",
        "print(fs)\n",
        "print(ps.shape)\n",
        "print (ps.mean(axis=1))\n",
        "print (ps.var(axis=1))\n",
        "\n",
        "#S_dB = librosa.power_to_db(ps, ref=np.max)\n",
        "librosa.display.specshow(ps, x_axis='time', sr=fs,hop_length=int(512/4))\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16000\n",
            "(13, 81)\n",
            "[-636.97328165  112.89538908  -55.27235917  -39.35811879  -26.96385187\n",
            "   14.45549824  -17.89835475   14.50935849  -10.4594912    -2.75587904\n",
            "  -11.64079737    4.61169338  -23.34611949]\n",
            "[148.17815613  50.86374099  84.80027241  17.56353333 103.31218257\n",
            "  39.67582151  38.52561358  55.89333215  26.13029353  23.96737997\n",
            "  26.78672775  43.68347741  23.70562007]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f5ba6d5b208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAAEGCAYAAADL3zbEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbM3MEnCyNTNL4P8BEzov5ySb2S0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}